{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Janssen & Rollins ABM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project constitutes an attempt to replicate the ABM from the paper \"Evolution of cooperation in asymmetric commons dilemmas\" by Marco A. Janssen and Nathan D. Rollins (2011). \n",
    "See http://www.sciencedirect.com/science/article/pii/S0167268111002599 for the paper. \n",
    "\n",
    "This version is only preliminary and still at an early stage. The code has not yet been cleaned up completely and still contains some unnecessary variables and functions. This will be gradually improved during the next weeks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This replication model relies on the Project Mesa Framework (see github.com/projectmesa).\n",
    "To get an understanding of how an ABM is built with mesa, it is useful to start with the basic blocks: the Agent and Model classes. These are imported from the mesa module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mesa import Model, Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the most basic level, an agent is initialized with a unique agent ID, and a variable where some information can be stored; as an example, each agent might have a score that is increased as the model runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Resource_Agent(Agent):\n",
    "    \n",
    "     def __init__(self, unique_id):\n",
    "        self.unique_id = unique_id\n",
    "        self.score = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Model class will later create a number of agents. To do this, both the number of agents and a function to create them will be needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Resource_Model(Model):\n",
    "    \n",
    "    \n",
    "    def __init__(self, N):\n",
    "        self.num_agents = N\n",
    "        self.create_agents()\n",
    "        \n",
    "    def create_agents(self):\n",
    "        for i in range(self.num_agents):\n",
    "            a = Resource_Agent(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above already is sufficient to create a working model, although the created agents will not do anything yet. A model with 5 agents can be created and run as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_model_one = Resource_Model(5)\n",
    "test_model_one.create_agents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a Scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to have the agents perform a certain action in each step of the model, a step function will have to be added to the Agent class. As an example, the agents will just increase their own score by 1 each round.\n",
    "\n",
    "In the Model class, it will have to be defined in what order the agents are activated, and how the model behaves at each step. Mesa includes several schedules, AAAAthe simplest being the BaseScheduler - the agents are activated in the order they were created each round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mesa import Model, Agent\n",
    "from mesa.time import RandomActivation\n",
    "\n",
    "class Resource_Agent(Agent):\n",
    "    \n",
    "    def __init__(self, unique_id):\n",
    "        self.unique_id = unique_id\n",
    "        self.score = 0\n",
    "        \n",
    "    def step(self, model):\n",
    "        self.score += 1\n",
    "\n",
    "class Resource_Model(Model):\n",
    "    \n",
    "    def __init__(self, N):\n",
    "        self.num_agents = N\n",
    "        self.schedule = RandomActivation(self)\n",
    "        self.create_agents()\n",
    "        \n",
    "    def create_agents(self):\n",
    "        for i in range(self.num_agents):\n",
    "            a = Resource_Agent(i)\n",
    "            self.schedule.add(a)\n",
    "            \n",
    "    def step(self):\n",
    "        self.schedule.step()\n",
    "\n",
    "    def run_model(self, steps):\n",
    "        for i in range(steps):\n",
    "            self.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model can now be run, with 5 agents increasing their score each round, which will be repeated for 10 rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Resource_Model(5)\n",
    "model.create_agents()\n",
    "model.run_model(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the Model to Janssen & Rollins'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to recreate the desired model, Agent and Model class will have to be modified to fit Janssen&Rollins Public Resource Game. The model's structure with two sub-steps per round will require changes to the Scheduler class as well.\n",
    "In this first approach, the algorithm by which agents respond to each other will be omitted, and a contribution and share takeout level will be chosen at random. [Note that this is equivalent to including the algorithm as described by formula 4 in J&R's paper and setting the parameter eta to 0. For values other than zero, the expected utility for each level of contribution will be taken into account.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the game's first round, each agent is endowed with a certain number of tokens (10), some of which can be contributed to the common public resource (CPR). Depending on the amount of contributions, this resource will be multiplied by some factor. In the second round, the agents take turns taking out some share of the CPR - the first agent gets to pick first, and so forth, until the last agent. Each step, contribution and takeout share will be chosen at random. The agents store the tokens they acquired during the game in a score variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from mesa import Model, Agent\n",
    "\n",
    "class Resource_Agent(Agent):\n",
    "\n",
    "    def __init__(self, unique_id):\n",
    "        self.unique_id = unique_id\n",
    "        self.score = 0\n",
    "        self.endowment = 10\n",
    "        self.contribution = random.randrange(0, 10, 1)\n",
    "        self.takeout_share = (random.randrange(0, 10, 1)) / 10\n",
    "        \n",
    "    def first_round(self, model):\n",
    "        self.endowment = 10\n",
    "        self.contribution = random.randrange(0, 10, 1)\n",
    "        self.score += (self.endowment - self.contribution)\n",
    "        \n",
    "    def second_round(self, model):\n",
    "        self.takeout_share = (random.randrange(0, 10, 1)) / 10\n",
    "        takeout = round(model.resource * self.takeout_share)\n",
    "        self.score += takeout\n",
    "        model.resource -= takeout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model class will determine the amount of tokens currently in the CPR, create a number of agents, and run for a number of steps. Janssen&Rollins describe an S-shaped function for the generated resource: more than one contributing agent is necessary to create a CPR. Mesa features a class for data colletion - this will be used to visualize the model's outcome in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mesa.datacollection import DataCollector\n",
    "\n",
    "class Resource_Model(Model):\n",
    "    \n",
    "    def __init__(self, N):\n",
    "        self.num_agents = N\n",
    "        self.schedule = BaseScheduler(self)\n",
    "        self.create_agents()\n",
    "        self.resource = 0\n",
    "        #creating a variable to determine the amount of CPR generated in this round:\n",
    "        self.sum_of_contributions = 0\n",
    "        #data collector\n",
    "        ar = {\"Score\": lambda ar: ar.score}\n",
    "        self.dc = DataCollector(agent_reporters = ar)\n",
    "        \n",
    "    def create_agents(self):            \n",
    "        for i in range(self.num_agents):\n",
    "            a = Resource_Agent(i)\n",
    "            self.schedule.add(a)\n",
    "            \n",
    "    def step(self):\n",
    "        self.schedule.step()\n",
    "        #collecting data\n",
    "        self.dc.collect(self)\n",
    "        #resetting the sum of contributions needed to determine the amount of CPR:\n",
    "        self.sum_of_contributions = 0\n",
    "        \n",
    "    def run_model(self, steps):\n",
    "        for i in range(steps):\n",
    "            self.step()\n",
    "            \n",
    "    def created_resource(self, sum_of_contributions):\n",
    "        if sum_of_contributions >= 0 and sum_of_contributions <= 10:\n",
    "            produced_resource = 0\n",
    "        elif sum_of_contributions >10 and sum_of_contributions <= 15:\n",
    "            produced_resource = 5\n",
    "        elif sum_of_contributions >15 and sum_of_contributions <= 20:\n",
    "            produced_resource = 20\n",
    "        elif sum_of_contributions >20 and sum_of_contributions <= 25:\n",
    "            produced_resource = 40\n",
    "        elif sum_of_contributions >25 and sum_of_contributions <= 30:\n",
    "            produced_resource = 60\n",
    "        elif sum_of_contributions >30 and sum_of_contributions <= 35:\n",
    "            produced_resource = 75\n",
    "        elif sum_of_contributions >35 and sum_of_contributions <= 40:\n",
    "            produced_resource = 85\n",
    "        elif sum_of_contributions >40 and sum_of_contributions <= 45:\n",
    "            produced_resource = 95\n",
    "        elif sum_of_contributions >45 and sum_of_contributions <= 50:\n",
    "            produced_resource = 100\n",
    "        return produced_resource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the Model's design with two rounds in each step, the scheduler class needs to be modified. Also, after each first round, the model's created_resource() function will be called to determine the amount of CPR generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BaseScheduler(object):\n",
    "    model = None\n",
    "    steps = 0\n",
    "    time = 0\n",
    "    agents = []\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.steps = 0\n",
    "        self.time = 0\n",
    "        self.agents = []\n",
    "\n",
    "    def add(self, agent):\n",
    "        self.agents.append(agent)\n",
    "\n",
    "    def remove(self, agent):\n",
    "        while agent in self.agents:\n",
    "            self.agents.remove(agent)\n",
    "\n",
    "    def step(self):\n",
    "    #Modified part.\n",
    "        for agent in self.agents:\n",
    "            agent.first_round(self.model)\n",
    "        self.model.resource = self.model.created_resource(self.model.sum_of_contributions)\n",
    "        for agent in self.agents:            \n",
    "            agent.second_round(self.model)\n",
    "        self.steps += 1\n",
    "        self.time += 1\n",
    "\n",
    "    def get_agent_count(self):\n",
    "        return len(self.agents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, this model will now be run for 10 steps including 5 agents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agents = 5\n",
    "runs = 10\n",
    "\n",
    "test_model = Resource_Model(agents)\n",
    "test_model.run_model(runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data collector collects data on each agents score, the scores of the five agents can be shown in a table using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEPCAYAAABFpK+YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x104465b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = test_model.dc.get_agent_vars_dataframe()\n",
    "data.reset_index(inplace=True)\n",
    "last_step_data = data[data.Step == (runs - 1)]\n",
    "\n",
    "x = range(agents)\n",
    "plt.ylabel(\"Score\")\n",
    "plt.xlabel(\"Agent No.\")\n",
    "plt.bar(x, last_step_data.Score, align = \"center\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model as described above is running like Janssen&Rollins' model in its basic structure, but since all moves are selected from a uniform random distribution, no useful data can be generated. To recreate the probabilistic choice function by which agents react to each other in the original model, more functions need to be implemented. This is done mainly in the Agent class; the Model class remains unchanged in its essential features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifications to the Agent class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, the model needs to be initialized with additional variables to store the model's parameters: alpha, beta and eta. Contribution and Takeout share in the game's first step remain uniformly random for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mesa import Model, Agent\n",
    "\n",
    "class Resource_Agent(Agent):\n",
    "\n",
    "    def __init__(self, unique_id, alpha, beta, eta):\n",
    "        self.unique_id = unique_id\n",
    "        self.score = 0\n",
    "        self.endowment = 10\n",
    "        self.contribution = random.randrange(0, 10, 1)\n",
    "        self.takeout_share = (random.randrange(0, 10, 1)) / 10\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.eta = eta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first_round and second_round functions, a list of probabilities from which a move is chosen replaces the uniformly random move choice. This list of probabilities is the heart of the model. It will be shown later how this list is generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def first_round(self, model):\n",
    "        self.endowment = 10\n",
    "        self.contribution = np.random.choice(11, p = self.k_probability_list_function(model))\n",
    "        self.score += (self.endowment - self.contribution)\n",
    "        \n",
    "    def second_round(self, model):\n",
    "        self.takeout_share = ((np.random.choice(11, p = self.l_probability_list_function(mode)) / 10))\n",
    "        takeout = round(model.resource * self.takeout_share)\n",
    "        self.score += takeout\n",
    "        model.resource -= takeout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First Round"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the model, a hypothetical utility for each possible amount of contribution to the CPR is calculated, dependent on the choices of Contribution and Share Takeout level of the other agents in the previous round. The utility of each k is \"transformed\" and divided by the sum of the \"transformed\" utilities for all ks. The transformation is done by multiplying the utility by the model parameter eta, and calculating the exponential function for this - \n",
    "See formula (4) in the Janssen&Rollins paper. \n",
    "Note that the following functions will later need to be reversed in order to make them callable for each other, but the approach is more easily understandable by introducing them in reverse order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def k_probability_list_function(self, model):\n",
    "        probability_list = []\n",
    "        for i in range(0, 11, 1):\n",
    "            probability_list.append(self.probability_of_k(i, model))\n",
    "        return probability_list\n",
    "    \n",
    "    def probability_of_k(k, model):\n",
    "        utility_of_k = self.utility_transformation(k, model)\n",
    "        probability = utility_of_k / self.transformed_utility_sum(model)\n",
    "        return probability\n",
    "    \n",
    "    def utility_transformation(self, k, model):\n",
    "        transformed_utility = math.exp(self.eta * (self.utility_of_k(k, model)))\n",
    "        return transformed_utility\n",
    "    \n",
    "    def transformed_utility_sum(self, model):\n",
    "        utility_sum = 0\n",
    "        for i in range(0, 11, 1):\n",
    "            calculation = self.utility_transformation(i, model)\n",
    "            utility_sum += calculation\n",
    "        return utility_sum   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given hypothetical utility for each k, each agent could now pick a contribution by probabilistic choice. In order for this to work, functions to determine hypothetical utilites for each k given the previous round's contributions and takeout shares of the other agents.\n",
    "The utility is dependend on an agent's earnings, the parameters alpha and beta, and the average earnings of the other players. See formula (3) in the J&R paper for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def utility_of_k(self, k, model):\n",
    "        if self.determine_wage(k, model) > self.determine_average_wage(k, model):\n",
    "            utility = self.determine_wage(k, model) - (self.alpha * (self.determine_wage(k, model) - self.determine_average_wage(k, model)))\n",
    "        elif self.determine_wage(k, model) == float(self.determine_average_wage(k, model)):\n",
    "            utility = self.determine_wage(k, model)\n",
    "        else:\n",
    "            utility = self.determine_wage(k, model) + (self.beta * (self.determine_average_wage(k, model) - self.determine_wage(k, model)))\n",
    "        return utility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to calculate the utility, additional functions to determine the wages for each respective player, as well as the average wage are needed. As follows from formula (4), the hypothetical wage for each contribution level k is dependent on the CPR that would be generated if all agents contributed the same amount as in the previous round, and the agent's upstream agents took out the same share as in the previous round - that is, the agent's potential takeout from the CPR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def determine_wage(self, k, model):\n",
    "        wage_player = (self.endowment - k) + self.determine_available_resource(k, model)\n",
    "        return wage_player"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned, the potentially available resource is determined by the CPR generated by all other agents - upstream and downstream - and the takeout share of the other players. The generated CPR is subject to the S-curve transformation described earlier, which is stored in the model class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def determine_available_resource(self, k, model):\n",
    "        contributions = self.last_round_sum_of_other_contributions(model) + k\n",
    "        resource = model.created_resource(contributions)\n",
    "        available_resource = resource * self.last_round_upstream_agents_combined_takeout_shares(model)\n",
    "        return available_resource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make the abovewritten function work, a function to determine the other agents and their position respective to the relevant agent are necessary.\n",
    "Then, functions to determine a given agent's last contribution and takeout level need to be added.\n",
    "In order for both to work, some additional variables in the agent class are added.\n",
    "The class is to be initialised with two new variables: a list for the agent's contributions in previous steps, past_contributions, and a list for the agent's takeout shares in past steps, past_takeout_shares.\n",
    "Two extra variables storing the total amount of tokens contributed to and taken out of the CPR will be added for the purpose of later data extraction.\n",
    "We will later utilize numpy to pick a move at random from a given list of probabilities, and using a math function to do a transformation of the utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Resource_Agent(Agent):\n",
    "\n",
    "    def __init__(self, unique_id, alpha, beta, eta):\n",
    "        self.unique_id = unique_id\n",
    "        self.score = 0\n",
    "        self.endowment = 10\n",
    "        self.contribution = random.randrange(0, 10, 1)\n",
    "        self.takeout_share = (random.randrange(0, 10, 1)) / 10\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.eta = eta\n",
    "        #New variables\n",
    "        self.past_contributions = [self.contribution]\n",
    "        self.past_takeout_shares = [self.takeout_share]\n",
    "        self.total_contribution = 0\n",
    "        self.total_amount_taken_out = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These variables need to be appended with the agent's contribution and takeout shares for each step. Also, the total_contribution and total_amount_taken_out variables are updated each round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    def first_round(self, model):\n",
    "        self.endowment = 10\n",
    "        self.contribution = np.random.choice(11, p = self.k_probability_list_function(model))\n",
    "        self.score += (self.endowment - self.contribution)\n",
    "        #Appending the past_contributions list\n",
    "        self.past_contributions.append(self.contribution)\n",
    "        #Increasing the total contributions\n",
    "        self.total_contribution += self.contribution\n",
    "        \n",
    "    def second_round(self, model):\n",
    "        self.takeout_share = ((np.random.choice(11, p = self.l_probability_list_function(model)) / 10))\n",
    "        takeout = round(model.resource * self.takeout_share)\n",
    "        self.score += takeout\n",
    "        model.resource -= takeout\n",
    "        #Appending the past_takeout_shares list\n",
    "        self.past_takeout_shares.append(self.takeout_share)\n",
    "        #Increasing the total amount taken out\n",
    "        self.total_amount_taken_out += takeout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to determine a list of upstream and downstream agents is added. First, each agent needs to be able to determine its own ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def get_id(self):\n",
    "        return self.unique_id        \n",
    "    \n",
    "    def determine_upstream_players(self, model):\n",
    "        \n",
    "        upstream_players = []\n",
    "        for agent in model.schedule.agents:\n",
    "            if agent.unique_id < self.get_id():\n",
    "                upstream_players.append(agent)\n",
    "        return upstream_players\n",
    "    \n",
    "    def determine_downstream_players(self, model):\n",
    "        \n",
    "        downstream_players = []\n",
    "        for agent in model.schedule.agents:\n",
    "            if agent.unique_id > self.get_id():\n",
    "                downstream_players.append(agent)\n",
    "        return downstream_players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's add functions for determining the sum of all other agents' contributions in the previous step of the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def last_round_sum_of_other_players_contributions(self, model):\n",
    "        sum_of_contributions = 0\n",
    "        for i in self.determine_upstream_players(model):\n",
    "            sum_of_contributions += i.past_contributions[model.schedule.steps]\n",
    "        for j in self.determine_downstream_players(model):\n",
    "            sum_of_contributions += j.past_contributions[model.schedule.steps]\n",
    "        return sum_of_contributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the previous round's takeout shares need to be combined - but only for the agents upstream of the respective agents. Also, this is not a sum of shares, but a multiplication of them, since the shares are expressed in a fraction of the total resource that is taken out. To get the remaining share, the term has to be muliplied by (1 - share) for each agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def last_round_upstream_agents_combined_takeout_shares(self, model):\n",
    "        remaining_share = 1\n",
    "        for i in self.determine_upstream_players(model):\n",
    "            remaining_share = remaining_share * (1 - i.past_takeout_shares[model.schedule.steps])\n",
    "        return remaining_share"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A given agent's wage can now be determined! Let's move on to the next part of the utility function, the average wage, which is equal to the amount of CPR that was generated plus the part of the endowment that was not invested - divided by the amount of agents. This calculation is based on the assumption that none of the CPR is \"wasted\", i.e., not taken out - which should be the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def determine_average_wage(self, k, model):\n",
    "        n = 0\n",
    "        for i in model.schedule.agents:\n",
    "            n += 1\n",
    "        generated_cpr = model.created_resource(self.last_round_sum_of_other_contributions(model) + k)\n",
    "        endowment_not_invested = (n * self.endowment) - (self.last_round_sum_of_other_contributions(model) + k)\n",
    "        total_wage = generated_cpr + endowment_not_invested\n",
    "        average_wage = total_wage / n\n",
    "        \n",
    "        return average_wage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which allows a calculation of the utility for each given k, and thus gives a list of probabilities for each k. What remains to be added is an analoguous algorithm for determining the takeout share, l. This is equivalent to function (5) in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second Round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def l_probability_list_function(self, model):\n",
    "        l_probability_list = []\n",
    "        for i in range(0, 11, 1):\n",
    "            l_probability_list.append(self.probability_of_l(i / 10, model))\n",
    "        return l_probability_list\n",
    "    \n",
    "    def probability_of_l(self, l, model):\n",
    "        utility_of_l = self.round_two_utility_transformation(l, model)\n",
    "        probability_of_l = utility_of_l / self.round_two_transformed_utility_sum(model)\n",
    "        return probability_of_l\n",
    "    \n",
    "    def round_two_utility_transformation(self, l, model):\n",
    "        round_two_transformed_utility = math.exp(self.eta * (self.determine_round_two_utility(l, model)))\n",
    "        return round_two_transformed_utility\n",
    "    \n",
    "    def round_two_transformed_utility_sum(self, model):\n",
    "        round_two_utility_sum = 0\n",
    "        for i in range(0, 11, 1):\n",
    "            calculation = self.round_two_utility_transformation(i / 10, model)\n",
    "            round_two_utility_sum += calculation\n",
    "        return round_two_utility_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equivalently to the first round, a function to determine a hypothetical utility for each takeout share l is needed. Unlike in the first round, however, the takeout shares of the upstream agents are known to the calculating agent, as is the size of the resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def determine_round_two_utility(self, l, model):\n",
    "        \n",
    "        if self.round_two_determine_wage(l, model) > float(self.round_two_average_wage(l, model)):\n",
    "            utility = self.round_two_determine_wage(l, model) - (self.alpha * (self.round_two_determine_wage(l, model) - self.round_two_average_wage(l, model)))\n",
    "        elif self.round_two_determine_wage(l, model) == float(self.round_two_average_wage(l, model)):\n",
    "            utility = self.round_two_determine_wage(l, model)\n",
    "        else:\n",
    "            utility = self.round_two_determine_wage(l, model) + (self.beta * (self.round_two_average_wage(l, model) - self.round_two_determine_wage(l, model)))\n",
    "        return utility\n",
    "\n",
    "    def round_two_determine_wage(self, l, model):\n",
    "        round_two_wage = (self.endowment - self.contribution) + (l * model.resource)\n",
    "        return round_two_wage\n",
    "     \n",
    "    def round_two_average_wage(self, l, model):\n",
    "        n = 0\n",
    "        for i in model.schedule.agents:\n",
    "            n += 1\n",
    "        this_round_contribution_sum = 0\n",
    "        for i in model.schedule.agents:\n",
    "            this_round_contribution_sum += i.contribution\n",
    "        generated_resource = model.created_resource(this_round_contribution_sum)\n",
    "        endowment_not_invested = (n * self.endowment) - this_round_contribution_sum\n",
    "        total_wage = generated_cpr + endowment_not_invested\n",
    "        average_wage = total_wage / n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complete Agent class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The necessary functions and variables to incorporate the algorithm into the Agent class are thus added. As mentioned earlier, the order in which the functions are defined need to be reversed, in order to make them callable in the right order. Which leaves us with the following complete Agent class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Resource_Agent(Agent):\n",
    "\n",
    "    def __init__(self, unique_id, alpha, beta, eta):\n",
    "        self.unique_id = unique_id\n",
    "        self.score = 0\n",
    "        self.endowment = 10\n",
    "        self.contribution = random.randrange(0, 10, 1)\n",
    "        self.takeout_share = (random.randrange(0, 10, 1)) / 10\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.eta = eta\n",
    "        self.past_contributions = [self.contribution]\n",
    "        self.past_takeout_shares = [self.takeout_share]\n",
    "        self.total_contribution = 0\n",
    "        self.total_amount_taken_out = 0\n",
    "        \n",
    "    def first_round(self, model):\n",
    "        self.endowment = 10\n",
    "        self.contribution = np.random.choice(11, p = self.k_probability_list_function(model))\n",
    "        self.score += (self.endowment - self.contribution)\n",
    "        self.past_contributions.append(self.contribution)\n",
    "        self.total_contribution += self.contribution\n",
    "        \n",
    "    def second_round(self, model):\n",
    "        self.takeout_share = ((np.random.choice(11, p = self.l_probability_list_function(model)) / 10))\n",
    "        takeout = round(model.resource * self.takeout_share)\n",
    "        self.score += takeout\n",
    "        model.resource -= takeout\n",
    "        self.past_takeout_shares.append(self.takeout_share)\n",
    "        self.total_amount_taken_out += takeout  \n",
    "        \n",
    "    #General functions\n",
    "    \n",
    "    def get_id(self):\n",
    "        return self.unique_id        \n",
    "\n",
    "    def determine_upstream_players(self, model):\n",
    "        \n",
    "        upstream_players = []\n",
    "        for agent in model.schedule.agents:\n",
    "            if agent.unique_id < self.get_id():\n",
    "                upstream_players.append(agent)\n",
    "        return upstream_players\n",
    "    \n",
    "    def determine_downstream_players(self, model):\n",
    "        \n",
    "        downstream_players = []\n",
    "        for agent in model.schedule.agents:\n",
    "            if agent.unique_id > self.get_id():\n",
    "                downstream_players.append(agent)\n",
    "        return downstream_players\n",
    "    \n",
    "    #Functions for Round 1\n",
    "    \n",
    "    def last_round_sum_of_other_contributions(self, model):\n",
    "        sum_of_contributions = 0\n",
    "        for i in self.determine_upstream_players(model):\n",
    "            sum_of_contributions += i.past_contributions[model.schedule.steps]\n",
    "        for j in self.determine_downstream_players(model):\n",
    "            sum_of_contributions += j.past_contributions[model.schedule.steps]\n",
    "        return sum_of_contributions\n",
    "    \n",
    "    def last_round_upstream_agents_combined_takeout_shares(self, model):\n",
    "        remaining_share = 1\n",
    "        for i in self.determine_upstream_players(model):\n",
    "            remaining_share = remaining_share * (1 - i.past_takeout_shares[model.schedule.steps])\n",
    "        return remaining_share\n",
    "    \n",
    "    def determine_available_resource(self, k, model):\n",
    "        contributions = self.last_round_sum_of_other_contributions(model) + k\n",
    "        resource = model.created_resource(contributions)\n",
    "        available_resource = resource * self.last_round_upstream_agents_combined_takeout_shares(model)\n",
    "        return available_resource\n",
    "    \n",
    "    def determine_wage(self, k, model):\n",
    "        wage_player = (self.endowment - k) + self.determine_available_resource(k, model)\n",
    "        return wage_player\n",
    "    \n",
    "    def determine_average_wage(self, k, model):\n",
    "        n = 0\n",
    "        for i in model.schedule.agents:\n",
    "            n += 1\n",
    "        generated_cpr = model.created_resource(self.last_round_sum_of_other_contributions(model) + k)\n",
    "        endowment_not_invested = (n * self.endowment) - (self.last_round_sum_of_other_contributions(model) + k)\n",
    "        total_wage = generated_cpr + endowment_not_invested\n",
    "        average_wage = total_wage / n\n",
    "        return average_wage\n",
    "    \n",
    "    def utility_of_k(self, k, model):\n",
    "        if self.determine_wage(k, model) > self.determine_average_wage(k, model):\n",
    "            utility = self.determine_wage(k, model) - (self.alpha * (self.determine_wage(k, model) - self.determine_average_wage(k, model)))\n",
    "        elif self.determine_wage(k, model) == self.determine_average_wage(k, model):\n",
    "            utility = self.determine_wage(k, model)\n",
    "        else:\n",
    "            utility = self.determine_wage(k, model) + (self.beta * (self.determine_average_wage(k, model) - self.determine_wage(k, model)))\n",
    "        return utility\n",
    "    \n",
    "    def utility_transformation(self, k, model):\n",
    "        transformed_utility = math.exp(self.eta * (self.utility_of_k(k, model)))\n",
    "        return transformed_utility\n",
    "\n",
    "    def transformed_utility_sum(self, model):\n",
    "        utility_sum = 0\n",
    "        for i in range(0, 11, 1):\n",
    "            calculation = self.utility_transformation(i, model)\n",
    "            utility_sum += calculation\n",
    "        return utility_sum   \n",
    "    \n",
    "    def probability_of_k(self, k, model):\n",
    "        utility_of_k = self.utility_transformation(k, model)\n",
    "        probability = utility_of_k / self.transformed_utility_sum(model)\n",
    "        return probability\n",
    "    \n",
    "    def k_probability_list_function(self, model):\n",
    "        probability_list = []\n",
    "        for i in range(0, 11, 1):\n",
    "            probability_list.append(self.probability_of_k(i, model))\n",
    "        return probability_list\n",
    "    \n",
    "    #Functions for Round 2\n",
    "    \n",
    "    def round_two_determine_wage(self, l, model):\n",
    "        round_two_wage = (self.endowment - self.contribution) + (l * model.resource)\n",
    "        return round_two_wage\n",
    "     \n",
    "    def round_two_average_wage(self, l, model):\n",
    "        n = 0\n",
    "        for i in model.schedule.agents:\n",
    "            n += 1\n",
    "        this_round_contribution_sum = 0\n",
    "        for i in model.schedule.agents:\n",
    "            this_round_contribution_sum += i.contribution\n",
    "        generated_resource = model.created_resource(this_round_contribution_sum)\n",
    "        endowment_not_invested = (n * self.endowment) - this_round_contribution_sum\n",
    "        total_wage = generated_resource + endowment_not_invested\n",
    "        average_wage = total_wage / n\n",
    "    \n",
    "    def determine_round_two_utility(self, l, model):\n",
    "        if self.round_two_determine_wage(l, model) > float(self.round_two_average_wage(l, model)):\n",
    "            utility = self.round_two_determine_wage(l, model) - (self.alpha * (self.round_two_determine_wage(l, model) - self.round_two_average_wage(l, model)))\n",
    "        elif self.round_two_determine_wage(l, model) == float(self.round_two_average_wage(l, model)):\n",
    "            utility = self.round_two_determine_wage(l, model)\n",
    "        else:\n",
    "            utility = self.round_two_determine_wage(l, model) + (self.beta * (self.round_two_average_wage(l, model) - self.round_two_determine_wage(l, model)))\n",
    "        return utility\n",
    "\n",
    "    def round_two_utility_transformation(self, l, model):\n",
    "        round_two_transformed_utility = math.exp(self.eta * (self.determine_round_two_utility(l, model)))\n",
    "        return round_two_transformed_utility\n",
    "    \n",
    "    def round_two_transformed_utility_sum(self, model):\n",
    "        round_two_utility_sum = 0\n",
    "        for i in range(0, 11, 1):\n",
    "            calculation = self.round_two_utility_transformation(i / 10, model)\n",
    "            round_two_utility_sum += calculation\n",
    "        return round_two_utility_sum\n",
    "\n",
    "    def probability_of_l(self, l, model):\n",
    "        utility_of_l = self.round_two_utility_transformation(l, model)\n",
    "        probability_of_l = utility_of_l / self.round_two_transformed_utility_sum(model)\n",
    "        return probability_of_l\n",
    "\n",
    "\n",
    "    def l_probability_list_function(self, model):\n",
    "        l_probability_list = []\n",
    "        for i in range(0, 11, 1):\n",
    "            l_probability_list.append(self.probability_of_l(i / 10, model))\n",
    "        return l_probability_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifications to the Model class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside the Model class, additional variables to pass on the parameters to the Agent class are the only modification. Also, the DataCollector will be updated in order to collect the total amount of contributions and takeouts for each agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Resource_Model(Model):\n",
    "    \n",
    "    def __init__(self, N, alpha, beta, eta):\n",
    "        self.num_agents = N\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.eta = eta\n",
    "        self.schedule = BaseScheduler(self)\n",
    "        self.create_agents()\n",
    "        self.resource = 0\n",
    "        self.sum_of_contributions = 0\n",
    "        ar = {\"Score\": lambda ar: ar.score, \n",
    "                \"Total_Contribution\": lambda at: at.total_contribution, \n",
    "                \"Total_Amount_Taken_Out\": lambda au: au.total_amount_taken_out}\n",
    "        self.dc = DataCollector(agent_reporters = ar)\n",
    "        \n",
    "    def create_agents(self):            \n",
    "        for i in range(self.num_agents):\n",
    "            a = Resource_Agent(i, alpha, beta, eta)\n",
    "            self.schedule.add(a)\n",
    "            \n",
    "    def step(self):\n",
    "        self.schedule.step()\n",
    "        self.dc.collect(self)\n",
    "        self.sum_of_contributions = 0\n",
    "        \n",
    "    def run_model(self, steps):\n",
    "        for i in range(steps):\n",
    "            self.step()\n",
    "            \n",
    "    def created_resource(self, sum_of_contributions):\n",
    "        if sum_of_contributions >= 0 and sum_of_contributions <= 10:\n",
    "            produced_resource = 0\n",
    "        elif sum_of_contributions >10 and sum_of_contributions <= 15:\n",
    "            produced_resource = 5\n",
    "        elif sum_of_contributions >15 and sum_of_contributions <= 20:\n",
    "            produced_resource = 20\n",
    "        elif sum_of_contributions >20 and sum_of_contributions <= 25:\n",
    "            produced_resource = 40\n",
    "        elif sum_of_contributions >25 and sum_of_contributions <= 30:\n",
    "            produced_resource = 60\n",
    "        elif sum_of_contributions >30 and sum_of_contributions <= 35:\n",
    "            produced_resource = 75\n",
    "        elif sum_of_contributions >35 and sum_of_contributions <= 40:\n",
    "            produced_resource = 85\n",
    "        elif sum_of_contributions >40 and sum_of_contributions <= 45:\n",
    "            produced_resource = 95\n",
    "        elif sum_of_contributions >45 and sum_of_contributions <= 50:\n",
    "            produced_resource = 100\n",
    "        return produced_resource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Algorithm Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model now being on par with the model in J&R's paper, it can now be run with specified parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-41816d89ff8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#Run the Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResource_Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mruns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-4c9b42001f49>\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(self, steps)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreated_resource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum_of_contributions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-4c9b42001f49>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum_of_contributions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-1d4eeb8a1ae5>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreated_resource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum_of_contributions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0magent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msecond_round\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-24530674e9bd>\u001b[0m in \u001b[0;36msecond_round\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msecond_round\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtakeout_share\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml_probability_list_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mtakeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtakeout_share\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtakeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-24530674e9bd>\u001b[0m in \u001b[0;36ml_probability_list_function\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0ml_probability_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m             \u001b[0ml_probability_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobability_of_l\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0ml_probability_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-24530674e9bd>\u001b[0m in \u001b[0;36mprobability_of_l\u001b[0;34m(self, l, model)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprobability_of_l\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0mutility_of_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround_two_utility_transformation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0mprobability_of_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutility_of_l\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround_two_transformed_utility_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mprobability_of_l\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-24530674e9bd>\u001b[0m in \u001b[0;36mround_two_utility_transformation\u001b[0;34m(self, l, model)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mround_two_utility_transformation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mround_two_transformed_utility\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetermine_round_two_utility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mround_two_transformed_utility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-24530674e9bd>\u001b[0m in \u001b[0;36mdetermine_round_two_utility\u001b[0;34m(self, l, model)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdetermine_round_two_utility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround_two_determine_wage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround_two_average_wage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m             \u001b[0mutility\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround_two_determine_wage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround_two_determine_wage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround_two_average_wage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround_two_determine_wage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround_two_average_wage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'NoneType'"
     ]
    }
   ],
   "source": [
    "#Model Parameters\n",
    "runs = 10\n",
    "agents = 5\n",
    "alpha = 0\n",
    "beta = 0\n",
    "eta = 0.5\n",
    "#Run the Model\n",
    "test_model = Resource_Model(agents, alpha, beta, eta)\n",
    "test_model.run_model(runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To analyze the model's output, a plot showing the total amount of contributions and takeouts for each player will be drawn. For this, first, the relevant data points in the DataCollector's data array need to be extracted: For the total contribution and takeouts, only the very last step of the game is relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = test_model.dc.get_agent_vars_dataframe()\n",
    "data.reset_index(inplace=True)\n",
    "\n",
    "model_data = test_model.dci.get_model_vars_dataframe()\n",
    "\n",
    "last_step_data = data[data.Step == (runs -1 )]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the diagram is plotted, using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "N = agents\n",
    "ind = np.arange(N)\n",
    "width = 0.28\n",
    "player_one = last_step_data[last_step_data.AgentID == 0]\n",
    "highest_takeout = int(player_one.Total_Amount_Taken_Out)\n",
    "\n",
    "\n",
    "rects1 = ax.bar(ind + width * 2, last_step_data.Total_Amount_Taken_Out, width, color = \"red\")\n",
    "rects2 = ax.bar(ind + width, last_step_data.Total_Contribution, width, color = \"blue\")\n",
    "\n",
    "ax.set_xlim(-width, len(ind) + width)\n",
    "ax.set_ylim(0, highest_takeout * 1.1)\n",
    "ax.set_ylabel(\"Points\")\n",
    "ax.set_title(\"Points by Agents\")\n",
    "xTickMarks = [\"Agent\" + str(i) for i in range(agents)]\n",
    "ax.set_xticks(ind + width)\n",
    "xtickNames = ax.set_xticklabels(xTickMarks)\n",
    "plt.setp(xtickNames, rotation = 45, fontsize = 10)\n",
    "\n",
    "ax.legend((rects2[0], rects1[0]), (\"SumOfContributions\", \"SumOfTakeouts\"))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
