{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Janssen & Rollins ABM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project constitutes an attempt to replicate the ABM from the paper \"Evolution of cooperation in asymmetric commons dilemmas\" by Marco A. Janssen and Nathan D. Rollins (2011). \n",
    "See http://www.sciencedirect.com/science/article/pii/S0167268111002599 for the paper. \n",
    "\n",
    "This version is only preliminary and still at an early stage. The code has not yet been cleaned up completely and still contains some unnecessary variables and functions. This will be gradually improved during the next weeks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This replication model relies on the Project Mesa Framework (see github.com/projectmesa).\n",
    "To get an understanding of how an ABM is built with mesa, it is useful to start with the basic blocks: the Agent and Model classes. These are imported from the mesa module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mesa import Model, Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the most basic level, an agent is initialized with a unique agent ID, and a variable where some information can be stored; as an example, each agent might have a score that is increased as the model runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Resource_Agent(Agent):\n",
    "    \n",
    "     def __init__(self, unique_id):\n",
    "        self.unique_id = unique_id\n",
    "        self.score = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Model class will later create a number of agents. To do this, both the number of agents and a function to create them will be needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Resource_Model(Model):\n",
    "    \n",
    "    \n",
    "    def __init__(self, N):\n",
    "        self.num_agents = N\n",
    "        self.create_agents()\n",
    "        \n",
    "    def create_agents(self):\n",
    "        for i in range(self.num_agents):\n",
    "            a = Resource_Agent(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above already is sufficient to create a working model, although the created agents will not do anything yet. A model with 5 agents can be created and run as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_model_one = Resource_Model(5)\n",
    "test_model_one.create_agents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a Scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to have the agents perform a certain action in each step of the model, a step function will have to be added to the Agent class. As an example, the agents will just increase their own score by 1 each round.\n",
    "\n",
    "In the Model class, it will have to be defined in what order the agents are activated, and how the model behaves at each step. Mesa includes several schedules, AAAAthe simplest being the BaseScheduler - the agents are activated in the order they were created each round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mesa import Model, Agent\n",
    "from mesa.time import RandomActivation\n",
    "\n",
    "class Resource_Agent(Agent):\n",
    "    \n",
    "    def __init__(self, unique_id):\n",
    "        self.unique_id = unique_id\n",
    "        self.score = 0\n",
    "        \n",
    "    def step(self, model):\n",
    "        self.score += 1\n",
    "\n",
    "class Resource_Model(Model):\n",
    "    \n",
    "    def __init__(self, N):\n",
    "        self.num_agents = N\n",
    "        self.schedule = RandomActivation(self)\n",
    "        self.create_agents()\n",
    "        \n",
    "    def create_agents(self):\n",
    "        for i in range(self.num_agents):\n",
    "            a = Resource_Agent(i)\n",
    "            self.schedule.add(a)\n",
    "            \n",
    "    def step(self):\n",
    "        self.schedule.step()\n",
    "\n",
    "    def run_model(self, steps):\n",
    "        for i in range(steps):\n",
    "            self.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model can now be run, with 5 agents increasing their score each round, which will be repeated for 10 rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Resource_Model(5)\n",
    "model.create_agents()\n",
    "model.run_model(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the Model to Janssen & Rollins'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to recreate the desired model, Agent and Model class will have to be modified to fit Janssen&Rollins Public Resource Game. The model's structure with two sub-steps per round will require changes to the Scheduler class as well.\n",
    "In this first approach, the algorithm by which agents respond to each other will be omitted, and a contribution and share takeout level will be chosen at random."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the game's first round, each agent is endowed with a certain number of tokens (10), some of which can be contributed to the common public resource (CPR). Depending on the amount of contributions, this resource will be multiplied by some factor. In the second round, the agents take turns taking out some share of the CPR - the first agent gets to pick first, and so forth, until the last agent. Each step, contribution and takeout share will be chosen at random. The agents store the tokens they acquired during the game in a score variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from mesa import Model, Agent\n",
    "\n",
    "class Resource_Agent(Agent):\n",
    "\n",
    "    def __init__(self, unique_id):\n",
    "        self.unique_id = unique_id\n",
    "        self.score = 0\n",
    "        self.endowment = 10\n",
    "        self.contribution = random.randrange(0, 10, 1)\n",
    "        self.takeout_share = (random.randrange(0, 10, 1)) / 10\n",
    "        \n",
    "    def first_round(self, model):\n",
    "        self.endowment = 10\n",
    "        self.contribution = random.randrange(0, 10, 1)\n",
    "        self.score += (self.endowment - self.contribution)\n",
    "        \n",
    "    def second_round(self, model):\n",
    "        self.takeout_share = (random.randrange(0, 10, 1)) / 10\n",
    "        takeout = round(model.resource * self.takeout_share)\n",
    "        self.score += takeout\n",
    "        model.resource -= takeout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model class will determine the amount of tokens currently in the CPR, create a number of agents, and run for a number of steps. Janssen&Rollins describe an S-shaped function for the generated resource: more than one contributing agent is necessary to create a CPR. Mesa features a class for data colletion - this will be used to visualize the model's outcome in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mesa.datacollection import DataCollector\n",
    "\n",
    "class Resource_Model(Model):\n",
    "    \n",
    "    def __init__(self, N):\n",
    "        self.num_agents = N\n",
    "        self.schedule = BaseScheduler(self)\n",
    "        self.create_agents()\n",
    "        self.resource = 0\n",
    "        #creating a variable to determine the amount of CPR generated in this round:\n",
    "        self.sum_of_contributions = 0\n",
    "        #data collector\n",
    "        ar = {\"Score\": lambda ar: ar.score}\n",
    "        self.dc = DataCollector(agent_reporters = ar)\n",
    "        \n",
    "    def create_agents(self):            \n",
    "        for i in range(self.num_agents):\n",
    "            a = Resource_Agent(i)\n",
    "            self.schedule.add(a)\n",
    "            \n",
    "    def step(self):\n",
    "        self.schedule.step()\n",
    "        #collecting data\n",
    "        self.dc.collect(self)\n",
    "        #resetting the sum of contributions needed to determine the amount of CPR:\n",
    "        self.sum_of_contributions = 0\n",
    "        \n",
    "    def run_model(self, steps):\n",
    "        for i in range(steps):\n",
    "            self.step()\n",
    "            \n",
    "    def created_resource(self, sum_of_contributions):\n",
    "        if sum_of_contributions >= 0 and sum_of_contributions <= 10:\n",
    "            produced_resource = 0\n",
    "        elif sum_of_contributions >10 and sum_of_contributions <= 15:\n",
    "            produced_resource = 5\n",
    "        elif sum_of_contributions >15 and sum_of_contributions <= 20:\n",
    "            produced_resource = 20\n",
    "        elif sum_of_contributions >20 and sum_of_contributions <= 25:\n",
    "            produced_resource = 40\n",
    "        elif sum_of_contributions >25 and sum_of_contributions <= 30:\n",
    "            produced_resource = 60\n",
    "        elif sum_of_contributions >30 and sum_of_contributions <= 35:\n",
    "            produced_resource = 75\n",
    "        elif sum_of_contributions >35 and sum_of_contributions <= 40:\n",
    "            produced_resource = 85\n",
    "        elif sum_of_contributions >40 and sum_of_contributions <= 45:\n",
    "            produced_resource = 95\n",
    "        elif sum_of_contributions >45 and sum_of_contributions <= 50:\n",
    "            produced_resource = 100\n",
    "        return produced_resource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the Model's design with two rounds in each step, the scheduler class needs to be modified. Also, after each first round, the model's created_resource() function will be called to determine the amount of CPR generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BaseScheduler(object):\n",
    "    model = None\n",
    "    steps = 0\n",
    "    time = 0\n",
    "    agents = []\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.steps = 0\n",
    "        self.time = 0\n",
    "        self.agents = []\n",
    "\n",
    "    def add(self, agent):\n",
    "        self.agents.append(agent)\n",
    "\n",
    "    def remove(self, agent):\n",
    "        while agent in self.agents:\n",
    "            self.agents.remove(agent)\n",
    "\n",
    "    def step(self):\n",
    "    #Modified part.\n",
    "        for agent in self.agents:\n",
    "            agent.first_round(self.model)\n",
    "        self.model.resource = self.model.created_resource(self.model.sum_of_contributions)\n",
    "        for agent in self.agents:            \n",
    "            agent.second_round(self.model)\n",
    "        self.steps += 1\n",
    "        self.time += 1\n",
    "\n",
    "    def get_agent_count(self):\n",
    "        return len(self.agents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, this model will now be run for 10 steps including 5 agents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agents = 5\n",
    "runs = 10\n",
    "\n",
    "test_model = Resource_Model(agents)\n",
    "test_model.run_model(runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data collector collects data on each agents score, the scores of the five agents can be shown in a table using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = test_model.dc.get_agent_vars_dataframe()\n",
    "data.reset_index(inplace=True)\n",
    "last_step_data = data[data.Step == (runs - 1)]\n",
    "\n",
    "x = range(agents)\n",
    "plt.ylabel(\"Score\")\n",
    "plt.xlabel(\"Agent No.\")\n",
    "plt.bar(x, last_step_data.Score, align = \"center\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model as described above is running like Janssen&Rollins' model in its basic structure, but since all moves are selected from a uniform random distribution, no useful data can be generated. To recreate the probabilistic choice function by which agents react to each other in the original model, more functions need to be implemented. This is done mainly in the Agent class; the Model class essentially remains unchanged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifications to the Agent class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, the model needs to be initialized with additional variables to store the model's parameters: alpha, beta and eta. Contribution and Takeout share in the game's first step remain uniformly random for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mesa import Model, Agent\n",
    "\n",
    "class Resource_Agent(Agent):\n",
    "\n",
    "    def __init__(self, unique_id, alpha, beta, eta):\n",
    "        self.unique_id = unique_id\n",
    "        self.score = 0\n",
    "        self.endowment = 10\n",
    "        self.contribution = random.randrange(0, 10, 1)\n",
    "        self.takeout_share = (random.randrange(0, 10, 1)) / 10\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.eta = eta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first_round and second_round functions, a list of probabilities from which a move is chosen replaces the uniformly random move choice. This list of probabilities is the heart of the model. It will be shown later how this list is generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def first_round(self, model):\n",
    "        self.endowment = 10\n",
    "        self.contribution = np.random.choice(11, p = self.k_probability_list_function(model))\n",
    "        self.score += (self.endowment - self.contribution)\n",
    "        \n",
    "    def second_round(self, model):\n",
    "        self.takeout_share = ((np.random.choice(11, p = self.l_probability_list) / 10))\n",
    "        takeout = round(model.resource * self.takeout_share)\n",
    "        self.score += takeout\n",
    "        model.resource -= takeout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the model, a hypothetical utility for each possible amount of contribution to the CPR is calculated, dependent on the choices of Contribution and Share Takeout level of the other agents in the previous round. The utility of each k is \"transformed\" and divided by the sum of the \"transformed\" utilities for all ks. The transformation is done by multiplying the utility by the model parameter eta, and calculating the exponential function for this - \n",
    "See formula (4) in the Janssen&Rollins paper. \n",
    "Note that the following functions will later need to be reversed in order to make them callable for each other, but the approach is more easily understandable by introducing them in reverse order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def k_probability_list_function(self, model):\n",
    "        probability_list = []\n",
    "        for i in range(0, 11, 1):\n",
    "            probability_list.append(self.probability_of_k(i, model))\n",
    "        return probability_list\n",
    "    \n",
    "    def probability_of_k(k, model):\n",
    "        utility_of_k = self.utility_transformation(k, model)\n",
    "        probability = utility_of_k / self.transformed_utility_sum(model)\n",
    "        return probability\n",
    "    \n",
    "    def utility_transformation(self, k, model):\n",
    "        transformed_utility = math.exp(self.eta * (self.determine_player_utility(k, model)))\n",
    "        return transformed_utility\n",
    "    \n",
    "    def transformed_utility_sum(self, model):\n",
    "        utility_sum = 0\n",
    "        for i in range(0, 11, 1):\n",
    "            calculation = self.utility_transformation(i, model)\n",
    "            utility_sum += calculation\n",
    "        return utility_sum   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given hypothetical utility for each k, each agent could now pick a contribution by probabilistic choice. In order for this to work, functions to determine hypothetical utilites for each k given the previous round's contributions and takeout shares of the other agents.\n",
    "The utility is dependend on an agent's earnings, the parameters alpha and beta, and the average earnings of the other players. See formula (3) in the J&R paper for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def utility_of_k(self, k, model):\n",
    "        if self.determine_wage(k, model) > self.determine_average_wage(k, model):\n",
    "            utility = self.determine_wage(k, model) - (self.alpha * (self.determine_wage(k, model) - self.determine_average_wage(k, model)))\n",
    "        elif self.determine_wage(k, model) == self.determine_average_wage(k, model):\n",
    "            utility = self.determine_wage(k, model)\n",
    "        else:\n",
    "            utility = self.determine_wage(k, model) + (self.beta * (self.determine_average_wage(k, model) - self.determine_wage(k, model)))\n",
    "        return utility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to calculate the utility, additional functions to determine the wages for each respective player, as well as the average wage are needed. As follows from formula (4), the hypothetical wage for each contribution level k is dependent on the CPR that would be generated if all agents contributed the same amount as in the previous round, and the agent's upstream agents took out the same share as in the previous round - that is, the agent's potential takeout from the CPR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def determine_wage(self, k, model):\n",
    "        potential_takeout = self.determine_available_resource(k, model) * self.upstream_players_takeout_level_combined(model)\n",
    "        wage_player = (self.endowment - k) + potential_takeout\n",
    "        return wage_player"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned, the potentially available resource is determined by the CPR generated by all other agents - upstream and downstream - and the takeout share of the other players. The generated CPR is subject to the S-curve transformation described earlier, which is stored in the model class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def determine_available_resource(self, k, model):\n",
    "        contributions = self.last_round_sum_of_upstream_players_contributions(model) + self.last_round_downstream_players_contributions(model) + k\n",
    "        resource = model.created_resource(contributions)\n",
    "        available_resource = resource - self.upstream_players_takeout_sum(model)\n",
    "        return available_resource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make the abovewritten function work, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifications to the Model class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside the Model class, additional variables to pass on the parameters to the Agent class are the only modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Resource_Model(Model):\n",
    "    \n",
    "    def __init__(self, N, alpha, beta, eta):\n",
    "        self.num_agents = N\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.eta = eta\n",
    "        self.schedule = BaseScheduler(self)\n",
    "        self.create_agents()\n",
    "        self.resource = 0\n",
    "        self.sum_of_contributions = 0\n",
    "        ar = {\"Score\": lambda ar: ar.score}\n",
    "        self.dc = DataCollector(agent_reporters = ar)\n",
    "        \n",
    "    def create_agents(self):            \n",
    "        for i in range(self.num_agents):\n",
    "            a = Resource_Agent(i)\n",
    "            self.schedule.add(a)\n",
    "            \n",
    "    def step(self):\n",
    "        self.schedule.step()\n",
    "        self.dc.collect(self)\n",
    "        self.sum_of_contributions = 0\n",
    "        \n",
    "    def run_model(self, steps):\n",
    "        for i in range(steps):\n",
    "            self.step()\n",
    "            \n",
    "    def created_resource(self, sum_of_contributions):\n",
    "        if sum_of_contributions >= 0 and sum_of_contributions <= 10:\n",
    "            produced_resource = 0\n",
    "        elif sum_of_contributions >10 and sum_of_contributions <= 15:\n",
    "            produced_resource = 5\n",
    "        elif sum_of_contributions >15 and sum_of_contributions <= 20:\n",
    "            produced_resource = 20\n",
    "        elif sum_of_contributions >20 and sum_of_contributions <= 25:\n",
    "            produced_resource = 40\n",
    "        elif sum_of_contributions >25 and sum_of_contributions <= 30:\n",
    "            produced_resource = 60\n",
    "        elif sum_of_contributions >30 and sum_of_contributions <= 35:\n",
    "            produced_resource = 75\n",
    "        elif sum_of_contributions >35 and sum_of_contributions <= 40:\n",
    "            produced_resource = 85\n",
    "        elif sum_of_contributions >40 and sum_of_contributions <= 45:\n",
    "            produced_resource = 95\n",
    "        elif sum_of_contributions >45 and sum_of_contributions <= 50:\n",
    "            produced_resource = 100\n",
    "        return produced_resource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
