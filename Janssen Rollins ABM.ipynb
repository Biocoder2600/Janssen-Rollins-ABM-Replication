{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Janssen & Rollins ABM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project constitutes an attempt to replicate the ABM from the paper \"Evolution of cooperation in asymmetric commons dilemmas\" by Marco A. Janssen and Nathan D. Rollins (2011). \n",
    "See http://www.sciencedirect.com/science/article/pii/S0167268111002599 for the paper. \n",
    "\n",
    "This version is only preliminary and still at a very early stage. The code has not yet been cleaned up and still contains some unnecessary variables and functions. This will be gradually improved during the next weeks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This replication model relies on the Project Mesa Framework for building the model (see github.com/projectmesa). Thus, the necessary classes are imported from mesa. Agent and Model classes are created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mesa import Model, Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Agent and Model class takes as arguments the model's parameters alpha, beta, and eta. Each agent is instantiated with a unique agent ID. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Resource_Agent(Agent):\n",
    "    \n",
    "     def __init__(self, unique_id, alpha, beta, eta):\n",
    "        \n",
    "        self.unique_id = unique_id\n",
    "        self.endowment = 10\n",
    "        self.score = 0\n",
    "        self.contribution = 0\n",
    "        self.takeout = 0\n",
    "        self.last_takeout_level = 0\n",
    "        self.takeout_level = 0\n",
    "        self.past_takeout_levels = [self.takeout_level]\n",
    "        self.past_contributions = [self.contribution]\n",
    "        self.sum_of_past_contributions = sum(self.past_contributions)\n",
    "        self.past_takeouts = [self.takeout]\n",
    "        self.last_contribution = 0\n",
    "        self.last_takeout = 0\n",
    "        self.alpha = alpha\n",
    "        self.beta = alpha\n",
    "        self.this_takeout = 0\n",
    "        self.takeout_sum = 0\n",
    "        self.contribution_sum = 0\n",
    "        self.eta = eta\n",
    "        self.k_probability_list = []\n",
    "        for s in range(0,11):\n",
    "            self.k_probability_list.append(0)\n",
    "        self.l_probability_list = []\n",
    "        for s in range(0,11):\n",
    "            self.l_probability_list.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Resource_Model(Model):\n",
    "    \n",
    "    \n",
    "    def __init__(self, N, alpha, beta, eta):\n",
    "        \n",
    "        self.running = True\n",
    "        self.num_agents = N\n",
    "        self.schedule = BaseScheduler(self)\n",
    "        self.create_agents()\n",
    "        self.resource = 0\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.eta = eta\n",
    "        self.contribution_sum = 0\n",
    "        #self.resource_list = []\n",
    "        ar = {\"Contribution\": lambda ab: ab.contribution, \n",
    "              \"Takeout\": lambda ac: ac.takeout,\n",
    "              \"TakeoutLevel\": lambda ah: ah.takeout_level,\n",
    "              \"SumOfTakeouts\": lambda af: af.takeout_sum, \n",
    "              \"SumOfContributions\": lambda aa: aa.contribution_sum,\n",
    "              \"ProbabilityOfZeroContribution\": lambda ay: ay.k_probability_list[0]}\n",
    "        self.dc = DataCollector(agent_reporters = ar)\n",
    "        self.generated_resource = 0\n",
    "        ad = {\"Generated_Resource\": lambda ad: ad.generated_resource}\n",
    "        self.dci = DataCollector(model_reporters = ad)\n",
    "        self.past_cprs = []\n",
    "        self.kept_tokens = 0\n",
    "        \n",
    "    def create_agents(self):\n",
    "        \n",
    "        for i in range(self.num_agents):\n",
    "            a = Resource_Agent(i, alpha, beta, eta)\n",
    "            self.schedule.add(a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mesa provides several Schedules that define in what order the different agents are activated during each tick of the model. Since agents are playing in a specific order each round in the Janssen&Rollins model, Mesa's BaseScheduler is used. As each tick of the model consists of two rounds - the investment and the share allocation round - the standard mesa scheduler has to be modified. Step functions are  added to the Model and Agent class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BaseScheduler(object):\n",
    "\n",
    "    model = None\n",
    "    steps = 0\n",
    "    time = 0\n",
    "    agents = []\n",
    "\n",
    "    def __init__(self, model):\n",
    "\n",
    "        self.model = model\n",
    "        self.steps = 0\n",
    "        self.time = 0\n",
    "        self.agents = []\n",
    "\n",
    "    def add(self, agent):\n",
    "\n",
    "        self.agents.append(agent)\n",
    "\n",
    "    def remove(self, agent):\n",
    "\n",
    "        while agent in self.agents:\n",
    "            self.agents.remove(agent)\n",
    "\n",
    "    def step(self):\n",
    "\n",
    "        for agent in self.agents:\n",
    "            agent.step_one(self.model)\n",
    "        self.model.resource = self.model.produced_resource()\n",
    "        for agent in self.agents:            \n",
    "            agent.step_two(self.model)\n",
    "        self.steps += 1\n",
    "        self.time += 1\n",
    "\n",
    "    def get_agent_count(self):\n",
    "\n",
    "        return len(self.agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mesa import Model, Agent\n",
    "\n",
    "class Resource_Agent(Agent):\n",
    "    \n",
    "    def __init__(self, unique_id, alpha, beta, eta):\n",
    "        \n",
    "        self.unique_id = unique_id\n",
    "        self.endowment = 10\n",
    "        self.score = 0\n",
    "        self.contribution = 0\n",
    "        self.takeout = 0\n",
    "        self.last_takeout_level = 0\n",
    "        self.takeout_level = 0\n",
    "        self.past_takeout_levels = [self.takeout_level]\n",
    "        self.past_contributions = [self.contribution]\n",
    "        self.sum_of_past_contributions = sum(self.past_contributions)\n",
    "        self.past_takeouts = [self.takeout]\n",
    "        self.last_contribution = 0\n",
    "        self.last_takeout = 0\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.this_takeout = 0\n",
    "        self.takeout_sum = 0\n",
    "        self.contribution_sum = 0\n",
    "        self.eta = eta\n",
    "        self.k_probability_list = []\n",
    "        for s in range(0,11):\n",
    "            self.k_probability_list.append(0)\n",
    "        self.l_probability_list = []\n",
    "        for s in range(0,11):\n",
    "            self.l_probability_list.append(0)\n",
    "\n",
    "    def step_one(self, model):\n",
    "         \n",
    "        self.first_tick(model)\n",
    "        self.determine_upstream_players(model)\n",
    "        self.get_last_contribution(model)\n",
    "        self.last_contribution = self.get_last_contribution(model)\n",
    "        self.upstream_player_last_contribution(model)\n",
    "        \n",
    "    def step_two(self, model):\n",
    "        \n",
    "        self.second_tick(model)\n",
    "        self.get_last_takeout(model)\n",
    "        self.last_takeout = self.get_last_takeout(model)\n",
    "        self.last_takeout_level = self.get_last_takeout_level(model)\n",
    "        self.this_takeout = self.get_this_takeout(model)\n",
    "        self.upstream_player_last_takeout(model)\n",
    "        \n",
    "    def first_tick(self, model):\n",
    "        \n",
    "        self.k_probability_list = self.k_probability_list_function(model)\n",
    "        self.endowment = 10\n",
    "        self.contribution = np.random.choice(11, p = self.k_probability_list_function(model))\n",
    "        self.past_contributions.append(self.contribution)\n",
    "        self.score += (self.endowment - self.contribution)\n",
    "        model.contribution_sum += self.contribution\n",
    "        model.kept_tokens += self.endowment - self.contribution\n",
    "        self.contribution_sum += self.contribution\n",
    "\n",
    "    def second_tick(self, model):\n",
    "        \n",
    "        self.l_probability_list = self.l_probability_list_function(model)\n",
    "        takeout_level = ((np.random.choice(11, p = self.l_probability_list) / 10))\n",
    "        self.takeout_level = takeout_level\n",
    "        self.takeout = round(takeout_level * model.resource)\n",
    "        if model.resource == 0:\n",
    "            self.takeout_level = 0\n",
    "        self.past_takeouts.append(self.takeout)\n",
    "        self.past_takeout_levels.append(self.takeout_level)\n",
    "        self.takeout_sum += self.takeout\n",
    "        self.score += self.takeout\n",
    "        model.resource -= self.takeout\n",
    "        model.generated_resource += self.takeout\n",
    "\n",
    "\n",
    "class Resource_Model(Model):\n",
    "    \n",
    "    \n",
    "    def __init__(self, N, alpha, beta, eta):\n",
    "        \n",
    "        self.running = True\n",
    "        self.num_agents = N\n",
    "        self.schedule = BaseScheduler(self)\n",
    "        self.create_agents()\n",
    "        self.resource = 0\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.eta = eta\n",
    "        self.contribution_sum = 0\n",
    "\n",
    "        ar = {\"Contribution\": lambda ab: ab.contribution, \n",
    "              \"Takeout\": lambda ac: ac.takeout,\n",
    "              \"TakeoutLevel\": lambda ah: ah.takeout_level,\n",
    "              \"SumOfTakeouts\": lambda af: af.takeout_sum, \n",
    "              \"SumOfContributions\": lambda aa: aa.contribution_sum,\n",
    "              \"ProbabilityOfZeroContribution\": lambda ay: ay.k_probability_list[0]}\n",
    "        self.dc = DataCollector(agent_reporters = ar)\n",
    "        self.generated_resource = 0\n",
    "        ad = {\"Generated_Resource\": lambda ad: ad.generated_resource}\n",
    "        self.dci = DataCollector(model_reporters = ad)\n",
    "        self.past_cprs = []\n",
    "        self.kept_tokens = 0\n",
    "        \n",
    "    def create_agents(self):\n",
    "        \n",
    "        for i in range(self.num_agents):\n",
    "            a = Resource_Agent(i, alpha, beta, eta)\n",
    "            self.schedule.add(a)\n",
    "\n",
    "    def step(self):\n",
    "\n",
    "        self.past_cprs.append(self.resource)\n",
    "        self.dc.collect(self)\n",
    "        self.schedule.step()\n",
    "        for agent in self.schedule.agents:\n",
    "            self.generated_resource += agent.contribution\n",
    "        self.dci.collect(self)\n",
    "        self.contribution_sum = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the algorithm for the agent behavior is implemented. This is done by adding functions mostly to the agent class, though some functions are added to the Model class as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import functools\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "from mesa import Model, Agent\n",
    "from mesa.datacollection import DataCollector\n",
    "from itertools import product\n",
    "from operator import itemgetter, attrgetter, methodcaller\n",
    "\n",
    "class Resource_Agent(Agent):\n",
    "    \n",
    "    def __init__(self, unique_id, alpha, beta, eta):\n",
    "        \n",
    "        self.unique_id = unique_id\n",
    "        self.endowment = 10\n",
    "        self.score = 0\n",
    "        self.contribution = 0\n",
    "        self.takeout = 0\n",
    "        self.last_takeout_level = 0\n",
    "        self.takeout_level = 0\n",
    "        self.past_takeout_levels = [self.takeout_level]\n",
    "        self.past_contributions = [self.contribution]\n",
    "        self.sum_of_past_contributions = sum(self.past_contributions)\n",
    "        self.past_takeouts = [self.takeout]\n",
    "        self.last_contribution = 0\n",
    "        self.last_takeout = 0\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.this_takeout = 0\n",
    "        self.takeout_sum = 0\n",
    "        self.contribution_sum = 0\n",
    "        self.eta = eta\n",
    "        self.k_probability_list = []\n",
    "        for s in range(0,11):\n",
    "            self.k_probability_list.append(0)\n",
    "        self.l_probability_list = []\n",
    "        for s in range(0,11):\n",
    "            self.l_probability_list.append(0)\n",
    "\n",
    "    def step_one(self, model):\n",
    "         \n",
    "        self.first_tick(model)\n",
    "        self.determine_upstream_players(model)\n",
    "        self.get_last_contribution(model)\n",
    "        self.last_contribution = self.get_last_contribution(model)\n",
    "        self.upstream_player_last_contribution(model)\n",
    "        \n",
    "    def step_two(self, model):\n",
    "        \n",
    "        \n",
    "        self.second_tick(model)\n",
    "        self.get_last_takeout(model)\n",
    "        self.last_takeout = self.get_last_takeout(model)\n",
    "        self.last_takeout_level = self.get_last_takeout_level(model)\n",
    "        self.this_takeout = self.get_this_takeout(model)\n",
    "        self.upstream_player_last_takeout(model)\n",
    "        \n",
    "    def first_tick(self, model):\n",
    "        \n",
    "        self.k_probability_list = self.k_probability_list_function(model)\n",
    "        self.endowment = 10\n",
    "        self.contribution = np.random.choice(11, p = self.k_probability_list_function(model))\n",
    "        self.past_contributions.append(self.contribution)\n",
    "        self.score += (self.endowment - self.contribution)\n",
    "        model.contribution_sum += self.contribution\n",
    "        model.kept_tokens += self.endowment - self.contribution\n",
    "        self.contribution_sum += self.contribution\n",
    "\n",
    "    def second_tick(self, model):\n",
    "        \n",
    "        self.l_probability_list = self.l_probability_list_function(model)\n",
    "        takeout_level = ((np.random.choice(11, p = self.l_probability_list) / 10))\n",
    "        self.takeout_level = takeout_level\n",
    "        self.takeout = round(takeout_level * model.resource)\n",
    "        if model.resource == 0:\n",
    "            self.takeout_level = 0\n",
    "        self.past_takeouts.append(self.takeout)\n",
    "        self.past_takeout_levels.append(self.takeout_level)\n",
    "        self.takeout_sum += self.takeout\n",
    "        self.score += self.takeout\n",
    "        model.resource -= self.takeout\n",
    "        model.generated_resource += self.takeout\n",
    "\n",
    "        \n",
    "    def upstream_player_last_contribution(self, model):\n",
    "        \n",
    "        if self.unique_id == 0:\n",
    "            upstream_player_last_contribution = [0]\n",
    "        else:\n",
    "            upstream_player_last_contribution = []\n",
    "            for i in self.determine_upstream_players(model):\n",
    "                upstream_player_last_contribution.append(i.last_contribution)\n",
    "        return upstream_player_last_contribution\n",
    "        \n",
    "    def downstream_player_last_contribution(self, model):\n",
    "        \n",
    "        if self.unique_id == 4:\n",
    "            downstream_player_last_contribution = [0]\n",
    "        else:\n",
    "            downstream_player_last_contribution = []\n",
    "            for i in self.determine_downstream_players(model):\n",
    "                downstream_player_last_contribution.append(i.last_contribution)\n",
    "        return downstream_player_last_contribution\n",
    "        \n",
    "    def upstream_player_last_takeout(self, model):\n",
    "        \n",
    "        if self.unique_id == 0:\n",
    "            upstream_player_last_takeout = [0]\n",
    "        else:\n",
    "            upstream_player_last_takeout = []\n",
    "            for i in self.determine_upstream_players(model):\n",
    "                upstream_player_last_takeout.append(i.last_takeout)\n",
    "        #if self.unique_id == 4:\n",
    "            #print(\"upstream players last takeout: \" + str(upstream_player_last_takeout))\n",
    "        return upstream_player_last_takeout\n",
    "        \n",
    "    def upstream_players_last_takeout_levels(self, model):\n",
    "        \n",
    "        if self.unique_id == 0:\n",
    "            upstream_players_last_takeout_levels = [0]\n",
    "        else:\n",
    "            upstream_players_last_takeout_levels = []\n",
    "            for i in self.determine_upstream_players(model):\n",
    "                upstream_players_last_takeout_levels.append(i.last_takeout_level)\n",
    "        return upstream_players_last_takeout_levels\n",
    "    \n",
    "    def upstream_players_last_takeout_levels_negative(self, model):\n",
    "        \n",
    "        if self.unique_id == 0:\n",
    "            upstream_players_last_takeout_levels_negative = [1]\n",
    "        else:\n",
    "            upstream_players_last_takeout_levels_negative = []\n",
    "            for i in self.determine_upstream_players(model):\n",
    "                upstream_players_last_takeout_levels_negative.append(1 - (i.last_takeout_level))\n",
    "        #print(\"UPSTREAM PLAYERS LAST TAKEOUT LEVELS NEG:   \"+ str(upstream_players_last_takeout_levels_negative))\n",
    "        return upstream_players_last_takeout_levels_negative\n",
    "\n",
    "    def get_id(self):\n",
    "\n",
    "        return self.unique_id        \n",
    "    \n",
    "    def determine_upstream_players(self, model):\n",
    "        \n",
    "        upstream_players = []\n",
    "        for agent in model.schedule.agents:\n",
    "            if agent.unique_id < self.get_id():\n",
    "                upstream_players.append(agent)\n",
    "        return upstream_players\n",
    "    \n",
    "    def determine_downstream_players(self, model):\n",
    "        \n",
    "        downstream_players = []\n",
    "        for agent in model.schedule.agents:\n",
    "            if agent.unique_id > self.get_id():\n",
    "                downstream_players.append(agent)\n",
    "        return downstream_players\n",
    "\n",
    "    def get_last_contribution(self, model):\n",
    "        \n",
    "        last_contribution = self.past_contributions[model.schedule.steps]\n",
    "        return last_contribution\n",
    "        \n",
    "    def get_last_takeout(self, model):\n",
    "        \n",
    "        last_takeout = self.past_takeouts[model.schedule.steps]\n",
    "        return last_takeout\n",
    "    \n",
    "    def get_last_takeout_level(self, model):\n",
    "        \n",
    "        last_takeout_level = self.past_takeout_levels[model.schedule.steps]\n",
    "        return last_takeout_level\n",
    "\n",
    "    def upstream_players_contribution_sum(self, model):\n",
    "        \n",
    "        contribution_sum = sum(self.upstream_player_last_contribution(model))\n",
    "        return contribution_sum\n",
    "                \n",
    "    def downstream_players_contribution_sum(self, model):\n",
    "        \n",
    "        downstream_contribution_sum = sum(self.downstream_player_last_contribution(model))\n",
    "        return downstream_contribution_sum\n",
    "        \n",
    "    def upstream_players_takeout_sum(self, model):\n",
    "        \n",
    "        takeout_sum = sum(self.upstream_player_last_takeout(model))\n",
    "        return takeout_sum\n",
    "    \n",
    "    def upstream_players_takeout_level_combined(self, model):\n",
    "        \n",
    "        takeout_level_combined = functools.reduce(lambda x, y: x*y, self.upstream_players_last_takeout_levels_negative(model))\n",
    "        #print(\"TAKEOUT LEVEL COMBINED \" + str(takeout_level_combined))\n",
    "        return takeout_level_combined\n",
    "        \n",
    "    \n",
    "    def determine_available_resource(self, k, model):\n",
    "        \n",
    "        contributions = self.upstream_players_contribution_sum(model) + self.downstream_players_contribution_sum(model) + k\n",
    "        resource = self.resource_transformation(contributions)\n",
    "        available_resource = resource - self.upstream_players_takeout_sum(model)\n",
    "        return available_resource\n",
    "        \n",
    "    def resource_transformation(self, contributions):\n",
    "        \n",
    "        if contributions >= 0 and contributions <= 10:\n",
    "            produced_resource = 0\n",
    "        elif contributions >10 and contributions <= 15:\n",
    "            produced_resource = 5\n",
    "        elif contributions >15 and contributions <= 20:\n",
    "            produced_resource = 20\n",
    "        elif contributions >20 and contributions <= 25:\n",
    "            produced_resource = 40\n",
    "        elif contributions >25 and contributions <= 30:\n",
    "            produced_resource = 60\n",
    "        elif contributions >30 and contributions <= 35:\n",
    "            produced_resource = 75\n",
    "        elif contributions >35 and contributions <= 40:\n",
    "            produced_resource = 85\n",
    "        elif contributions >40 and contributions <= 45:\n",
    "            produced_resource = 95\n",
    "        elif contributions >45 and contributions <= 50:\n",
    "            produced_resource = 100\n",
    "        return produced_resource\n",
    "\n",
    "        \n",
    "    def determine_wage(self, k, model):\n",
    "        \n",
    "        potential_takeout = self.determine_available_resource(k, model) * self.upstream_players_takeout_level_combined(model)\n",
    "        wage_player = (self.endowment - k) + potential_takeout\n",
    "        return wage_player\n",
    "            \n",
    "    def determine_other_wages(self, model):\n",
    "        \n",
    "        other_takeouts = []\n",
    "        for i in model.schedule.agents:\n",
    "            if i.unique_id != self.get_id():\n",
    "                other_takeouts.append(i.last_takeout)\n",
    "        other_contributions_net = []\n",
    "        for j in model.schedule.agents:\n",
    "            if j.unique_id != self.get_id():\n",
    "                other_contributions_net.append(self.endowment - (j.last_contribution))\n",
    "        other_wages = other_takeouts + other_contributions_net\n",
    "        return other_wages\n",
    "        \n",
    "    def determine_average_wage(self, k, model):\n",
    "        \n",
    "        n = 0\n",
    "        for i in model.schedule.agents:\n",
    "            n += 1\n",
    "        average_wage = (self.determine_wage(k, model) + sum(self.determine_other_wages(model))) / n\n",
    "        return average_wage\n",
    "    \n",
    "    def determine_player_utility(self, k, model):\n",
    "        \n",
    "        if self.determine_wage(k, model) > self.determine_average_wage(k, model):\n",
    "            utility = self.determine_wage(k, model) - (self.alpha * (self.determine_wage(k, model) - self.determine_average_wage(k, model)))\n",
    "        elif self.determine_wage(k, model) == self.determine_average_wage(k, model):\n",
    "            utility = self.determine_wage(k, model)\n",
    "        else:\n",
    "            utility = self.determine_wage(k, model) + (self.beta * (self.determine_average_wage(k, model) - self.determine_wage(k, model)))\n",
    "        return utility\n",
    "\n",
    "    def utility_transformation(self, k, model):\n",
    "        \n",
    "        transformed_utility = math.exp(self.eta * (self.determine_player_utility(k, model)))\n",
    "        return transformed_utility\n",
    "\n",
    "    def transformed_utility_sum(self, model):\n",
    "    \n",
    "        utility_sum = 0\n",
    "        for i in range(0, 11, 1):\n",
    "            calculation = self.utility_transformation(i, model)\n",
    "            utility_sum += calculation\n",
    "        return utility_sum\n",
    "    \n",
    "    def probability_of_k(self, k, model):\n",
    "    \n",
    "        utility_of_k = self.utility_transformation(k, model)\n",
    "        probability = utility_of_k / self.transformed_utility_sum(model)\n",
    "        return probability\n",
    "    \n",
    "    def k_probability_list_function(self, model):\n",
    "    \n",
    "        probability_list = []\n",
    "        for i in range(0, 11, 1):\n",
    "            probability_list.append(self.probability_of_k(i, model))\n",
    "        return probability_list\n",
    "    \n",
    "    \"\"\"\n",
    "    Functions for share allocation in phase 2\n",
    "    \"\"\"\n",
    "    \n",
    "    def get_this_takeout(self, model):\n",
    "        \n",
    "        this_takeout = self.past_takeouts[model.schedule.steps + 1]\n",
    "        return this_takeout\n",
    "\n",
    "    def upstream_player_this_takeout(self, model):\n",
    "        \n",
    "        if self.unique_id == 0:\n",
    "            upstream_player_this_takeout = [0]\n",
    "        else:\n",
    "            upstream_player_this_takeout = []\n",
    "            for i in self.determine_upstream_players(model):\n",
    "                upstream_player_this_takeout.append(i.this_takeout)\n",
    "        return upstream_player_this_takeout\n",
    "    \n",
    "    def upstream_players_this_takeout_sum(self, model):\n",
    "        \n",
    "        this_takeout_sum = sum(self.upstream_player_this_takeout(model))\n",
    "        return this_takeout_sum\n",
    "        \n",
    "    def phase_two_average_wage(self, model):\n",
    "        \n",
    "        n = 0\n",
    "        for i in model.schedule.agents:\n",
    "            n += 1\n",
    "        two_resource = model.resource\n",
    "        phase_two_average_wage = (two_resource + (n * self.endowment)) / n\n",
    "        return phase_two_average_wage\n",
    "    \n",
    "        \n",
    "    def phase_two_determine_wage(self, l, model):\n",
    "        \n",
    "        phase_two_wage = (self.endowment - self.contribution) + (l * model.resource)\n",
    "        return phase_two_wage\n",
    "        \n",
    "    def determine_phase_two_utility(self, l, model):\n",
    "        \n",
    "        if self.phase_two_determine_wage(l, model) > self.phase_two_average_wage(model):\n",
    "            utility = self.phase_two_determine_wage(l, model) - (self.alpha * (self.phase_two_determine_wage(l, model) - self.phase_two_average_wage(model)))\n",
    "        elif self.phase_two_determine_wage(l, model) == self.phase_two_average_wage(model):\n",
    "            utility = self.phase_two_determine_wage(l, model)\n",
    "        else:\n",
    "            utility = self.phase_two_determine_wage(l, model) + (self.beta * (self.phase_two_average_wage(model) - self.phase_two_determine_wage(l, model)))\n",
    "        return utility\n",
    "\n",
    "    def phase_two_utility_transformation(self, l, model):\n",
    "        \n",
    "        phase_two_transformed_utility = math.exp(self.eta * (self.determine_phase_two_utility(l, model)))\n",
    "        return phase_two_transformed_utility\n",
    "\n",
    "    def phase_two_transformed_utility_sum(self, model):\n",
    "    \n",
    "        phase_two_utility_sum = 0\n",
    "        for i in range(0, 11, 1):\n",
    "            calculation = self.phase_two_utility_transformation(i / 10, model)\n",
    "            phase_two_utility_sum += calculation\n",
    "        return phase_two_utility_sum\n",
    "        \n",
    "    def probability_of_l(self, l, model):\n",
    "    \n",
    "        utility_of_l = self.phase_two_utility_transformation(l, model)\n",
    "        probability_of_l = utility_of_l / self.phase_two_transformed_utility_sum(model)\n",
    "        return probability_of_l\n",
    "        \n",
    "    def l_probability_list_function(self, model):\n",
    "    \n",
    "        l_probability_list = []\n",
    "        for i in range(0, 11, 1):\n",
    "            l_probability_list.append(self.probability_of_l(i / 10, model))\n",
    "        return l_probability_list\n",
    "\n",
    "        \n",
    "class Resource_Model(Model):\n",
    "    \n",
    "    \n",
    "    def __init__(self, N, alpha, beta, eta):\n",
    "        \n",
    "        self.running = True\n",
    "        self.num_agents = N\n",
    "        self.schedule = BaseScheduler(self)\n",
    "        self.create_agents()\n",
    "        self.resource = 0\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.eta = eta\n",
    "        self.contribution_sum = 0\n",
    "        ar = {\"Contribution\": lambda ab: ab.contribution, \n",
    "              \"Takeout\": lambda ac: ac.takeout,\n",
    "              \"TakeoutLevel\": lambda ah: ah.takeout_level,\n",
    "              \"SumOfTakeouts\": lambda af: af.takeout_sum, \n",
    "              \"SumOfContributions\": lambda aa: aa.contribution_sum,\n",
    "              \"ProbabilityOfZeroContribution\": lambda ay: ay.k_probability_list[0]}\n",
    "        self.dc = DataCollector(agent_reporters = ar)\n",
    "        self.generated_resource = 0\n",
    "        ad = {\"Generated_Resource\": lambda ad: ad.generated_resource}\n",
    "        self.dci = DataCollector(model_reporters = ad)\n",
    "        self.past_cprs = []\n",
    "        self.kept_tokens = 0\n",
    "\n",
    "        \n",
    "    def create_agents(self):\n",
    "        \n",
    "        for i in range(self.num_agents):\n",
    "            a = Resource_Agent(i, alpha, beta, eta)\n",
    "            self.schedule.add(a)\n",
    "          \n",
    "    def produced_resource(self):\n",
    "        \n",
    "        if self.contribution_sum >= 0 and self.contribution_sum <= 10:\n",
    "            produced_resource = 0\n",
    "        elif self.contribution_sum >10 and self.contribution_sum <= 15:\n",
    "            produced_resource = 5\n",
    "        elif self.contribution_sum >15 and self.contribution_sum <= 20:\n",
    "            produced_resource = 20\n",
    "        elif self.contribution_sum >20 and self.contribution_sum <= 25:\n",
    "            produced_resource = 40\n",
    "        elif self.contribution_sum >25 and self.contribution_sum <= 30:\n",
    "            produced_resource = 60\n",
    "        elif self.contribution_sum >30 and self.contribution_sum <= 35:\n",
    "            produced_resource = 75\n",
    "        elif self.contribution_sum >35 and self.contribution_sum <= 40:\n",
    "            produced_resource = 85\n",
    "        elif self.contribution_sum >40 and self.contribution_sum <= 45:\n",
    "            produced_resource = 95\n",
    "        elif self.contribution_sum >45 and self.contribution_sum <= 50:\n",
    "            produced_resource = 100\n",
    "        return produced_resource\n",
    "          \n",
    "          \n",
    "    def step(self):\n",
    "\n",
    "        self.past_cprs.append(self.resource)\n",
    "        self.dc.collect(self)\n",
    "        self.schedule.step()\n",
    "        for agent in self.schedule.agents:\n",
    "            self.generated_resource += agent.contribution\n",
    "        self.dci.collect(self)\n",
    "        self.contribution_sum = 0\n",
    "        \n",
    "    def determine_resource(self):\n",
    "        \n",
    "        return self.generated_resource\n",
    "        \n",
    "    def determine_total_payoff(self):\n",
    "        \n",
    "        total_payoff = self.kept_tokens + self.generated_resource\n",
    "        return total_payoff\n",
    "    \n",
    "    def run_model(self, steps):\n",
    "        \n",
    "        for i in range(steps):\n",
    "            self.step()\n",
    "            if i % 100 == 0:\n",
    "                print(\"\")\n",
    "                print(\"########################################\")\n",
    "                print(\"\")\n",
    "                print(\"STEP \" + str(i) + \" of \" + str(steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BatchRunner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this model includes a stochastic element and results for several combinations of parameters need to be comparable, mesa's BatchRunner class is used to enable this. Some changes need to be made to the original class in order to incorporate the two-step property of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BatchRunner(object):\n",
    "\n",
    "\n",
    "    model_cls = None\n",
    "    parameter_values = {}\n",
    "    iterations = 1\n",
    "\n",
    "    model_reporters = {}\n",
    "    agent_reporters = {}\n",
    "\n",
    "    model_vars = {}\n",
    "    agent_vars = {}\n",
    "\n",
    "    def __init__(self, model_cls, parameter_values, iterations=1,\n",
    "                 max_steps=1000, model_reporters=None, agent_reporters=None):\n",
    "        self.model_cls = model_cls\n",
    "        self.parameter_values = {param: self.make_iterable(vals)\n",
    "                                 for param, vals in parameter_values.items()}\n",
    "        self.iterations = iterations\n",
    "        self.max_steps = max_steps\n",
    "\n",
    "        self.model_reporters = model_reporters\n",
    "        self.agent_reporters = agent_reporters\n",
    "\n",
    "        if self.model_reporters:\n",
    "            self.model_vars = {}\n",
    "\n",
    "        if self.agent_reporters:\n",
    "            self.agent_vars = {}\n",
    "            \n",
    "    def run_all(self):\n",
    "        params = self.parameter_values.keys()\n",
    "        param_ranges = self.parameter_values.values()\n",
    "        run_count = 0\n",
    "        for param_values in list(product(*param_ranges)):\n",
    "            kwargs = dict(zip(params, param_values))\n",
    "            for _ in range(self.iterations):\n",
    "                model = self.model_cls(**kwargs)\n",
    "                self.run_model(model)\n",
    "                # Collect and store results:\n",
    "                if self.model_reporters:\n",
    "                    key = tuple(list(param_values) + [run_count])\n",
    "                    self.model_vars[key] = self.collect_model_vars(model)\n",
    "                if self.agent_reporters:\n",
    "                    for agent_id, reports in self.collect_agent_vars.items():\n",
    "                        key = tuple(list(param_values) + [run_count, agent_id])\n",
    "                        self.agent_vars[key] = reports\n",
    "                run_count += 1\n",
    "                \n",
    "    def run_model(self, model):\n",
    "        while model.running and model.schedule.steps < self.max_steps:\n",
    "            model.step()\n",
    "            \n",
    "    def collect_model_vars(self, model):\n",
    "        model_vars = {}\n",
    "        for var, reporter in self.model_reporters.items():\n",
    "            model_vars[var] = reporter(model)\n",
    "        return model_vars\n",
    "        \n",
    "    def collect_agent_vars(self, model):\n",
    "        agent_vars = {}\n",
    "        for agent in model.schedule.agents:\n",
    "            agent_record = {}\n",
    "            for var, reporter in self.agent_reporters.items():\n",
    "                agent_record[var] = reporter(agent)\n",
    "            agent_vars[agent.unique_id] = agent_record\n",
    "        return agent_vars\n",
    "        \n",
    "    def get_model_vars_dataframe(self):\n",
    "        index_col_names = list(self.parameter_values.keys())\n",
    "        index_col_names.append(\"Run\")\n",
    "        records = []\n",
    "        for key, val in self.model_vars.items():\n",
    "            record = dict(zip(index_col_names, key))\n",
    "            for k, v in val.items():\n",
    "                record[k] = v\n",
    "            records.append(record)\n",
    "        return pd.DataFrame(records)\n",
    "        \n",
    "    def get_agent_vars_dataframe(self):\n",
    "        index_col_names = list(self.parameter_values.keys())\n",
    "        index_col_names += [\"Run\", \"AgentID\"]\n",
    "        records = []\n",
    "        for key, val in self.agent_vars.items():\n",
    "            record = dict(zip(index_col_names, key))\n",
    "            for k, v in val.items():\n",
    "                record[k] = v\n",
    "            records.append(record)\n",
    "        return pd.DataFrame(records)\n",
    "        \n",
    "    @staticmethod\n",
    "    def make_iterable(val):\n",
    "        if hasattr(val, \"__iter__\") and type(val) is not str:\n",
    "            return val\n",
    "        else:\n",
    "            return [val]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Batch runner can now be run, using a set of parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "runs = 10\n",
    "agents = 5\n",
    "eta = 0.5\n",
    "\n",
    "alpha_values = []\n",
    "for i in range(-10, 11):\n",
    "    x = i/10\n",
    "    alpha_values.append(x)\n",
    "\n",
    "beta_values = []\n",
    "for i in range(-10, 11):\n",
    "    x = i/10\n",
    "    beta_values.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'alpha' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-be4d8a950cf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResource_Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mparam_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"N\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"alpha\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0malpha_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"beta\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbeta_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"eta\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel_reporter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"Generated_Resource\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdetermine_final_resource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Total_Payoff\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdetermine_total_payoff\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchRunner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResource_Model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_reporter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'alpha' is not defined"
     ]
    }
   ],
   "source": [
    "model = Resource_Model(agents, alpha, beta, eta)   \n",
    "param_values = {\"N\": 5, \"alpha\": alpha_values, \"beta\": beta_values, \"eta\": 0.5}\n",
    "model_reporter = {\"Generated_Resource\": determine_final_resource, \"Total_Payoff\": determine_total_payoff}\n",
    "batch = BatchRunner(Resource_Model, param_values, iterations, runs, model_reporter)\n",
    "batch.run_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make the results interpretable, scatterplots for different values of alpha and beta are included:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out = batch.get_model_vars_dataframe()\n",
    "\n",
    "plt.scatter(out.alpha, out.Generated_Resource)\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"Generated Resource\")\n",
    "\n",
    "plt.scatter(out.alpha, out.Generated_Resource)\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"beta\")\n",
    "plt.ylabel(\"Generated Resource\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 3D model showing the level of CPR for different values of alpha and beta (as is the Janssen & Rollins paper) is yet to be implemented."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
