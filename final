# -*- coding: utf-8 -*-
"""
Created on Sat Sep  3 12:38:36 2016

@author: Joe
"""

import random
import math
import sys
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from mesa import Model, Agent
from mesa.datacollection import DataCollector
from itertools import product
from mpl_toolkits.mplot3d import *


"""
Reproduction: Set the corresponding variable to "1" to reproduce results for
one of the figures in the Thesis. Please set all other of the variables to "0".
"""

figure3_2 = 0 #check! #doublechecked
figure3_3 = 0 #check! #doublechecked
figure3_5 = 0 #check! #
figure3_6 = 1 #check!
figure3_7 = 0 #check!
figure3_8 = 0 #check!

if figure3_2 == 1:
    print("Reproducing Fig. 3.2")
elif figure3_3 == 1:
    print("Reproducing Fig. 3.3")
elif figure3_5 == 1:
    print("Reproducing Fig. 3.5")
elif figure3_6 == 1:
    print("Reproducing Fig. 3.6")
elif figure3_7 == 1:
    print("Reproducing Fig. 3.7")
elif figure3_8 == 1:
    print("Reproducing Fig. 3.8")
    
figurecheck = figure3_2 + figure3_3  + figure3_5  + figure3_6  + figure3_7 + figure3_8
if figurecheck > 1:
    sys.exit("Please select only one figure")
    
"""
Begin of Actual Model
"""

#Agent Class, generated by the Model class
class Resource_Agent(Agent):

#Initial Conditions
    def __init__(self, unique_id, alpha, beta, eta):
        self.unique_id = unique_id
        self.score = 0 #accumulating score
        self.subscore = 0 #score of this round only
        self.endowment = 1
        self.contribution = 0
        self.takeout_share = (random.randrange(0, 11, 1)) / 10
        self.alpha = alpha
        self.beta = beta
        self.eta = eta
        self.past_contributions = [self.contribution]
        self.past_takeout_shares = [self.takeout_share]
        self.total_contribution = 0
        self.total_amount_taken_out = 0

#Resource Provision Phase      
    def first_round(self, model):
        self.endowment = 1
        self.subscore = 0
        self.contribution = ((np.random.choice(11, p = self.investment_p(model))) / 10)
        self.score += (self.endowment - self.contribution)
        self.subscore += (self.endowment - self.contribution)
        self.past_contributions.append(self.contribution)
        self.total_contribution += self.contribution
        model.sum_of_contributions += self.contribution
        
#Resource Allocation Phase
    def second_round(self, model):
        takeout_share = ((np.random.choice(11, p = self.extraction_p(model))) / 10)
        takeout = round(model.resource * takeout_share, 1)
        actual_takeout_share = round((takeout / (model.resource + 0.000000001)), 1)
        self.takeout_share = actual_takeout_share
        if takeout_share <= 0:
            takeout_share = 0
        self.past_takeout_shares.append(actual_takeout_share)
        self.score += takeout
        self.subscore += takeout
        model.resource -= takeout
        if model.resource < 0:
            model.resource = 0
        self.total_amount_taken_out += takeout
      
#Variant of the Allocation phase for the linear public good game. The resource
#provision phase is the same in both types of games.      
    def sym_second_round(self, model):
        takeout = model.equal_share
        self.takeout_share = 0.2
        self.past_takeout_shares.append(0.2)
        self.score += takeout
        self.subscore += takeout
        model.resource -= takeout
        if model.resource < 0:
            model.resource = 0
        self.total_amount_taken_out += takeout

        
#General functions, needed for the probabilistic choice calculations   
    def get_id(self):
        return self.unique_id        

    def determine_upstream_players(self, model):
        upstream_players = []
        for agent in model.schedule.agents:
            if agent.unique_id < self.get_id():
                upstream_players.append(agent)
        return upstream_players
    
    def determine_downstream_players(self, model):
        downstream_players = []
        for agent in model.schedule.agents:
            if agent.unique_id > self.get_id():
                downstream_players.append(agent)
        return downstream_players
        
    def last_round_sum_of_other_contributions(self, model):
        sum_of_contributions = 0
        for i in self.determine_upstream_players(model):
            sum_of_contributions += i.past_contributions[model.schedule.steps]
        for j in self.determine_downstream_players(model):
            sum_of_contributions += j.past_contributions[model.schedule.steps]
        return sum_of_contributions
    
    def last_round_upstream_agents_combined_takeout_shares(self, model):
        remaining_share = 1
        for i in self.determine_upstream_players(model):
            remaining_share = remaining_share * (1 - i.past_takeout_shares[model.schedule.steps])
        return remaining_share
    
    def this_round_upstream_players_combined_takeout_shares(self, model):
        remaining_share = 1
        for i in self.determine_upstream_players(model):
            remaining_share = remaining_share * (1 - i.takeout_share)
        return remaining_share

#Probabilistic Choice functions        
    def investment_p(self, model):
        xj = self.last_round_sum_of_other_contributions(model)
        yj = self.last_round_upstream_agents_combined_takeout_shares(model)
        u_list = []
        for x in range(0, 11, 1):
            wi = 1 - x/10 + yj * model.created_resource(x/10 + xj)
            wavg = 1 - 0.2 * x/10 - 0.2 * xj + 0.2 * model.created_resource(x/10 + xj)
            u_of_x = wi - self.alpha * max(wi - wavg, 0) + self.beta * max(wavg - wi, 0)
            u_list.append(u_of_x)
            p_list = []
            denominator = 0
            for u in u_list:
                denominator += math.exp(self.eta * u)
            for u in u_list:
                    numerator = math.exp(self.eta * u)
                    p_list.append(numerator / denominator)
        return p_list
        
    def extraction_p(self, model):
        x = self.contribution
        xij = 0
        for i in model.schedule.agents:
            xij += i.contribution
        yj = self.this_round_upstream_players_combined_takeout_shares(model)
        u_list = []
        for y in range(0, 11, 1):
            wi = 1 - x + y/10 * yj * model.created_resource(xij)
            wavg = 1 - 0.2 * xij + 0.2 * model.created_resource(xij)
            u_of_x = wi - self.alpha * max(wi - wavg, 0) + self.beta * max(wavg - wi, 0)
            u_list.append(u_of_x)
            p_list = []
            denominator = 0
            for u in u_list:
                denominator += math.exp(self.eta * u)
            if denominator == 0:
                for u in u_list:
                    p_list.append(1/11)
            else:
                for u in u_list:
                    numerator = math.exp(self.eta * u)
                    p_list.append(numerator / denominator)
        return p_list

#Model Class     
class Resource_Model(Model):
    
#Initial Conditions
    def __init__(self, N, alpha, beta, eta, fa, r, group_id = 1):
        self.num_agents = N
        self.alpha = alpha
        self.beta = beta
        self.eta = eta
        self.schedule = BaseScheduler(self)
        self.create_agents()
        self.resource = 0
        self.sum_of_contributions = 0
        #variables collected by mesa's DataCollector class
        ar = {"Score": lambda ar: ar.score, 
                "Total_Contribution": lambda at: at.total_contribution, 
                "Total_Amount_Taken_Out": lambda au: au.total_amount_taken_out}
        self.dc = DataCollector(agent_reporters = ar)
        # Variables needed for mesa's BatchRunner to work later
        self.total_produced_resource = 0
        ad = {"Generated_CPR": lambda ad: ad.total_produced_resource}
        self.dci = DataCollector(model_reporters = ad)
        self.running = True
        self.fa = fa # frequency of asymmetric games being played. Set to 1 for
        #only asymmetric games, and to 0 for only linear games being played.
        self.r = r #parameter in the resource generation function for the
        #linear games.
        self.equal_share = 0 #Determining the share each player receives in the
        #linear symmetric game.
        self.group_id = group_id
        
    def create_agents(self):            
        for i in range(self.num_agents):
            a = Resource_Agent(i, self.alpha, self.beta, self.eta)
            self.schedule.add(a)
            
    def step(self):
        asym = np.random.choice(2, p = [self.fa, (1 - self.fa)])#Determines 
        #whether an asymmetric or lienar game is being played.
        if asym == 0:
            self.schedule.step() #step function defined in mesa's BaseScheduler Class.
            #An asymmetric commons game is being played for this round.
        else:
            self.schedule.symstep() #Manually added function in mesa's BaseScheduler Class.
            #A linear public good game is being played in this round.
        self.dc.collect(self) # collecting data
        self.total_produced_resource += self.created_resource(self.sum_of_contributions)
        self.dci.collect(self) # collecting data
        self.sum_of_contributions = 0
        
    def run_model(self, steps):
        for i in range(steps):
            self.step()

    def determine_generated_cpr(self): #Needed to collect CPR levels for runs with multiple iterations
        generated_cpr = self.total_produced_resource
        return generated_cpr

         
    def created_resource(self, sum_of_contributions): #resource function
        if sum_of_contributions >= 0 and sum_of_contributions < 1:
            produced_resource = 0
        elif sum_of_contributions >=1 and sum_of_contributions < 1.5:
            produced_resource = 0.5
        elif sum_of_contributions >=1.5 and sum_of_contributions < 2:
            produced_resource = 2
        elif sum_of_contributions >= 2 and sum_of_contributions < 2.5:
            produced_resource = 4
        elif sum_of_contributions >= 2.5 and sum_of_contributions < 3:
            produced_resource = 6
        elif sum_of_contributions >=3 and sum_of_contributions < 3.5:
            produced_resource = 7.5
        elif sum_of_contributions >=3.5 and sum_of_contributions < 4:
            produced_resource = 8.5
        elif sum_of_contributions >=4 and sum_of_contributions < 4.5:
            produced_resource = 9.5
        elif sum_of_contributions >=4.5 and sum_of_contributions <= 5:
            produced_resource = 10
        return produced_resource
      
#Needed to determine distribution of extractions between agent positions      
    def determine_agent_total_takeout(self):
        takeout_list = []
        for i in self.schedule.agents:
            takeout = i.total_amount_taken_out
            takeout_list.append(takeout)
        return takeout_list
        
#Needed to determine distribution of investments between agent positions        
    def determine_agent_total_contribution(self):
        contribution_list = []
        for i in self.schedule.agents:
            contribution = i.total_contribution
            contribution_list.append(contribution)
        return contribution_list


#BaseScheduler + BatchRunner: classes imported from mesa, modified as described
class BaseScheduler(object):
    model = None
    steps = 0
    time = 0
    agents = []

    def __init__(self, model):
        self.model = model
        self.steps = 0
        self.time = 0
        self.agents = []

    def add(self, agent):
        self.agents.append(agent)

    def remove(self, agent):
        while agent in self.agents:
            self.agents.remove(agent)

    def step(self):
    #Modified part. Adding a first (provision) and second(allocation) round
        for agent in self.agents:
            agent.first_round(self.model)
        self.model.resource = self.model.created_resource(self.model.sum_of_contributions)
        for agent in self.agents:            
            agent.second_round(self.model)
        self.steps += 1
        self.time += 1
     
    #Added function for the linear goods game 
    def symstep(self):
        for agent in self.agents:
            agent.first_round(self.model)
        self.model.resource = self.model.r * (self.model.sum_of_contributions)
        self.model.equal_share = (self.model.resource / 5)
        for agent in self.agents:            
            agent.sym_second_round(self.model)
        self.steps += 1
        self.time += 1


    def get_agent_count(self):
        return len(self.agents)

class BatchRunner(object):


    model_cls = None
    parameter_values = {}
    iterations = 1

    model_reporters = {}
    agent_reporters = {}

    model_vars = {}
    agent_vars = {}

    def __init__(self, model_cls, parameter_values, iterations=1,
                 max_steps=1000, model_reporters=None, agent_reporters=None):
        self.model_cls = model_cls
        self.parameter_values = {param: self.make_iterable(vals)
                                 for param, vals in parameter_values.items()}
        self.iterations = iterations
        self.max_steps = max_steps

        self.model_reporters = model_reporters
        self.agent_reporters = agent_reporters

        if self.model_reporters:
            self.model_vars = {}

        if self.agent_reporters:
            self.agent_vars = {}
            
    def run_all(self): # modified to give some progress info while the model is running
        params = self.parameter_values.keys()
        param_ranges = self.parameter_values.values()
        run_count = 0
        s = 1
        g = len(alpha_values) * len(beta_values)
        if figure3_6 == 1 or figure3_7 == 1:
            print("running...")
        elif figure3_8 ==1:
            pass
        else:
            print("running iteration " + str(s) + " of " + str(iterations) + "...")
        for param_values in list(product(*param_ranges)):
            kwargs = dict(zip(params, param_values))
            for _ in range(self.iterations):
                model = self.model_cls(**kwargs)
                self.run_model(model)
                # Collect and store results:
                if self.model_reporters:
                    key = tuple(list(param_values) + [run_count])
                    self.model_vars[key] = self.collect_model_vars(model)
                if self.agent_reporters:
                    for agent_id, reports in self.collect_agent_vars.items():
                        key = tuple(list(param_values) + [run_count, agent_id])
                        self.agent_vars[key] = reports
                run_count += 1
                if figure3_6 != 1 and figure3_7 != 1 and figure3_8 != 1:
                    if run_count % g == 0:
                        s += 1
                        if s <= iterations:
                            print("running iteration " + str(s) + " of " + str(iterations) + str("..."))
                        else:
                            print("")
                            print("Done!")
                         
    def run_model(self, model):
        while model.running and model.schedule.steps < self.max_steps:
            model.step()
            
    def collect_model_vars(self, model):
        model_vars = {}
        for var, reporter in self.model_reporters.items():
            model_vars[var] = reporter(model)
        return model_vars
        
    def collect_agent_vars(self, model):
        agent_vars = {}
        for agent in model.schedule.agents:
            agent_record = {}
            for var, reporter in self.agent_reporters.items():
                agent_record[var] = reporter(agent)
            agent_vars[agent.unique_id] = agent_record
        return agent_vars
        
    def get_model_vars_dataframe(self):
        index_col_names = list(self.parameter_values.keys())
        index_col_names.append("Run")
        records = []
        for key, val in self.model_vars.items():
            record = dict(zip(index_col_names, key))
            for k, v in val.items():
                record[k] = v
            records.append(record)
        return pd.DataFrame(records)
        
    def get_agent_vars_dataframe(self):
        index_col_names = list(self.parameter_values.keys())
        index_col_names += ["Run", "AgentID"]
        records = []
        for key, val in self.agent_vars.items():
            record = dict(zip(index_col_names, key))
            for k, v in val.items():
                record[k] = v
            records.append(record)
        return pd.DataFrame(records)
        
    @staticmethod
    def make_iterable(val):
        if hasattr(val, "__iter__") and type(val) is not str:
            return val
        else:
            return [val]
                
    
#Functions for determining amounts of generated CPR, as well as ginis for investments and extractions,
# and distribution of investments and extractions between agent positions
def determine_final_resource(model):
    final_resource = model.determine_generated_cpr()
    return final_resource
    
def determine_takeouts(model):
    takeouts = model.determine_agent_total_takeout()
    return takeouts
    
def determine_contributions(model):
    contributions = model.determine_agent_total_contribution()
    return contributions

def compute_gini_takeouts(model):
    denominator = 0
    divisor = 0
    agent_takeout_sum = [agent.total_amount_taken_out for agent in model.schedule.agents]
    for xi in agent_takeout_sum:
        for xj in agent_takeout_sum:
            divisor += xj
            a = xi - xj
            if a < 0:
                a = -1 * a
            denominator += a
    gini = denominator / ((divisor * 2) + 0.000000000000000001)
    return gini
    
def compute_gini_contributions(model):
    denominator = 0
    divisor = 0
    agent_contribution_sum = [agent.total_contribution for agent in model.schedule.agents]
    for xi in agent_contribution_sum:
        for xj in agent_contribution_sum:
            divisor += xj
            a = xi - xj
            if a < 0:
                a = -1 * a
            denominator += a
    gini = denominator / ((divisor * 2) + 0.000000000000000001)
    return gini

#Function for running the cultural selection model    
def imitation_model(iterations, groups, m, epsilon, fa):
    group_list = []
    #creating groups of agents
    for j in range(groups):
        group_list.append(Resource_Model(agents, alpha, beta, eta, fa, r, j))
    for g in range(iterations):    
        for h in range(groups):
            group_list[h].run_model(runs)
        for h in range(groups):
            for c in group_list[h].schedule.agents:
                noise = np.random.normal(0, 0.1)
                c.alpha += noise
                if c.alpha > 1:
                    c.alpha = 1
                noise = np.random.normal(0, 0.1)
                c.beta += noise
                if c.beta > c.alpha:
                    c.beta = c.alpha
        for h in range(groups):
            for x in group_list[h].schedule.agents:
                if x.alpha > 1:
                    x.alpha = 1
                if x.beta > x.alpha:
                    x.beta = x.alpha
                agent_imitation = np.random.choice(2, p = [(1-m), m])
                w_i = x.score
                jchoice = np.random.choice(agents)
                if agent_imitation == 0:
                    j = group_list[h].schedule.agents[jchoice]
                    w_j = j.score
                    imit_p = (w_j / (w_i + w_j + 0.0000000000000001))
                    imit = np.random.choice(2, p = [imit_p, (1 - imit_p)])
                    if imit == 0:
                        x.alpha = j.alpha
                        x.beta = j.beta
                else:           
                    gchoice = np.random.choice(groups)
                    j = group_list[gchoice].schedule.agents[jchoice]
                    w_j = j.score
                    imit_p = (w_j / (w_i + w_j + 0.00000000000000001))
                    imit = np.random.choice(2, p = [imit_p, (1 - imit_p)])
                    if imit == 0:
                        x.alpha = j.alpha
                        x.beta = j.beta
                            
        average_fitness = 0
        for h in range(groups):
            average_fitness += group_list[h].total_produced_resource
        average_fitness = (average_fitness/groups)
        for h in range(groups):
            group_imitation = np.random.choice(2, p=[epsilon, (1 - epsilon)])
            if group_imitation == 0: 
                fitness_i = (group_list[h].total_produced_resource / (average_fitness + 0.000000000001))
                s_i = 0
                for a in group_list[h].schedule.agents:
                    if a.subscore >= 1:
                        s_i +=1
                s_i = (s_i / agents)
                gchoice = np.random.choice(groups)
                fitness_j = (group_list[gchoice].total_produced_resource / (average_fitness + 0.0000000000000001))
                s_j = 0
                for b in group_list[gchoice].schedule.agents:
                    if b.subscore >= 1:
                        s_j += 1
                s_j = (s_j / agents)
                imit_p = ((1 + ((fitness_j * s_j) - (fitness_i * s_i))) / 2)
                if imit_p < 0:
                    imit_p = 0
                elif imit_p > 1:
                    imit_p = 1
                imit = np.random.choice(2, p = [imit_p, (1 - imit_p)])
                if imit == 0:
                    z = 0
                    for x in group_list[h].schedule.agents:
                        j = group_list[gchoice].schedule.agents[z]
                        x.alpha = j.alpha
                        x.beta = j.beta
                        z += 1
                else:
                    z = 0
                    for x in group_list[gchoice].schedule.agents:
                        j = group_list[h].schedule.agents[z]
                        x.alpha = j.alpha
                        x.beta = j.beta
                        z += 1
#Data Collection
    average_cpr = 0
    average_alpha = 0
    average_beta = 0
    for h in range(groups):
        average_cpr += group_list[h].total_produced_resource
        for j in group_list[h].schedule.agents:
            average_alpha += (j.alpha / agents)
            average_beta += (j.beta / agents)
    average_cpr = (average_cpr / iterations)
    average_cpr = (average_cpr / groups)
    average_cpr = (average_cpr / runs)
    average_beta = (average_beta / groups)
    average_alpha = (average_alpha / groups)
    output_list = [average_cpr, average_alpha, average_beta]
    return output_list


#Model Parameter settings.
runs = 10 #corresponding to c
agents = 5
#alpha = 1 #Used for the run with variable eta
#beta = 1 #Used for the run with variable eta
#eta = 15
#fa = 0 #frequency of asymmetric games played.
r = 2 #parameter in the linear resource generating function.
iterations = 50 #iterations for each parameter combination
eta_values = [0, 0.125, 0.25, 0.375, 0.5, 0.75, 1, 1.5, 2, 3, 4, 6, 8, 12, 15, 16, 32]
#Used for the run with variable eta
alpha_values = [] #the range of values for alpha with which the iterated model is run
for i in range(-10, 11):
    x = i/10
    alpha_values.append(x)
beta_values = [] #the range of values for beta with which the iterated model is run
for i in range(-10, 11):
    x = i/10
    beta_values.append(x)
#visualization settings
visu3d = 0

if figure3_2 == 1:
    visu3d = 1
    runs = 10
    agents = 5
    eta = 0.5
    fa = 1
    iterations = 50
    #parameters for the BatchRunner, i.e. the iterated model
    param_values = {"N": agents, "alpha": alpha_values, "beta": beta_values, "eta": eta,
                "fa": fa, "r": r}
    model_reporter = {"Generated_CPR": determine_final_resource,
                  "Gini_Contributions": compute_gini_contributions, 
                  "Gini_Takeouts": compute_gini_takeouts}
    batch = BatchRunner(Resource_Model, param_values, iterations, runs, model_reporter)
    
if figure3_3 == 1:
    visu3d = 1
    runs = 10
    agents = 5
    eta = 0.5
    fa = 0
    iterations = 50
    #parameters for the BatchRunner, i.e. the iterated model
    param_values = {"N": agents, "alpha": alpha_values, "beta": beta_values, "eta": eta,
                "fa": fa, "r": r}
    model_reporter = {"Generated_CPR": determine_final_resource,
                  "Gini_Contributions": compute_gini_contributions, 
                  "Gini_Takeouts": compute_gini_takeouts}
    batch = BatchRunner(Resource_Model, param_values, iterations, runs, model_reporter)
    

if figure3_5 == 1:
    visu3d = 1
    runs = 10
    agents = 5
    eta = 15
    fa = 1
    iterations = 50
    #parameters for the BatchRunner, i.e. the iterated model
    param_values = {"N": agents, "alpha": alpha_values, "beta": beta_values, "eta": eta,
                "fa": fa, "r": r}
    model_reporter = {"Generated_CPR": determine_final_resource,
                  "Gini_Contributions": compute_gini_contributions, 
                  "Gini_Takeouts": compute_gini_takeouts}
    batch = BatchRunner(Resource_Model, param_values, iterations, runs, model_reporter)
    
if figure3_6 == 1:
    runs = 10
    agents = 5
    fa = 1
    iterations = 300
    #parameters for the BatchRunner, i.e. the iterated model
    param_values = {"N": agents, "alpha": -1, "beta": -1, "eta": eta_values,
                "fa": fa, "r": r}
    model_reporter = {"Generated_CPR": determine_final_resource,
                  "Gini_Contributions": compute_gini_contributions, 
                  "Gini_Takeouts": compute_gini_takeouts}
    batch = BatchRunner(Resource_Model, param_values, iterations, runs, model_reporter)
    batch.run_all()
    out = batch.get_model_vars_dataframe() # Stores the collected data
    grouped = out.groupby("eta").mean()
    y = grouped.Generated_CPR
    ylist = np.array(y)
    ylist = ylist / 10
    fig = plt.figure()
    ax1 = fig.add_subplot(111)
    ax1.set_xlabel("eta")
    ax1.set_ylabel("CPR level")
    ax1.set_title("alpha = -1, beta = -1")
    ax1.plot(eta_values, ylist)
    ax1.axvline(15, color = "red")
    ax1.axhline(0.075, color = "green")
    ax1.set_xscale('log', basex = 2)
    fig.show()
    
    
    param_values2 = {"N": agents, "alpha": 1, "beta": -0.2, "eta": eta_values,
                "fa": fa, "r": r}
    batch2 = BatchRunner(Resource_Model, param_values2, iterations, runs, model_reporter)
    batch2.run_all()
    out2 = batch2.get_model_vars_dataframe() # Stores the collected data
    grouped2 = out2.groupby("eta").mean()
    y2 = grouped2.Generated_CPR
    ylist2 = np.array(y2)
    ylist2 = ylist2 / 10
    fig2 = plt.figure()
    ax2 = fig2.add_subplot(111)
    ax2.set_xlabel("eta")
    ax2.set_ylabel("CPR level")
    ax2.set_title("alpha = 1, beta = -0.2")
    ax2.plot(eta_values, ylist2)
    ax2.axvline(15, color = "red")
    ax2.axhline(2, color = "green")
    ax2.set_xscale('log', basex = 2)
    fig2.show()

    param_values3 = {"N": agents, "alpha": 1, "beta": 1, "eta": eta_values,
                "fa": fa, "r": r}
    batch3 = BatchRunner(Resource_Model, param_values3, iterations, runs, model_reporter)
    batch3.run_all()
    out3 = batch3.get_model_vars_dataframe() # Stores the collected data    
    grouped3 = out3.groupby("eta").mean()
    y3 = grouped3.Generated_CPR
    ylist3 = np.array(y3)
    ylist3 = ylist3 / 10
    fig3 = plt.figure()
    ax3 = fig3.add_subplot(111)
    ax3.set_xlabel("eta")
    ax3.set_ylabel("CPR level")
    ax3.set_title("alpha = 1, beta = 1")
    ax3.plot(eta_values, ylist3)
    ax3.axvline(15, color = "red")
    ax3.axhline(7, color = "green")
    ax3.set_xscale('log', basex = 2)
    fig3.show()

if figure3_7 == 1:
    runs = 10
    agents = 5
    eta = 15
    fa = 1
    iterations = 200
    model_reporter = {"Takeouts": determine_takeouts, "Contributions": determine_contributions}
    scale = iterations * runs
    ind = np.arange(agents)
    width = 0.28

    param_values = {"N": agents, "alpha": 0.85, "beta": 0.4, "eta": eta,
                "fa": fa, "r": r}
    batch = BatchRunner(Resource_Model, param_values, iterations, runs, model_reporter)
    batch.run_all()
    out = batch.get_model_vars_dataframe()
    contrib = out.Contributions[0]
    for j in range(1, iterations):
        subcon = out.Contributions[j]
        contrib = [contrib[i]+subcon[i] for i in range(len(contrib))]
    contrib = [(contrib[i]/scale) for i in range(len(contrib))]
    extrac = out.Takeouts[0]
    for j in range(1, iterations):
        subex = out.Takeouts[j]
        extrac = [extrac[i]+subex[i] for i in range(len(extrac))]
    extrac = [(extrac[i]/scale) for i in range(len(extrac))]    
    fig = plt.figure()
    ax = fig.add_subplot(111)
    rects1 = ax.bar(ind + width, contrib, width, color = "blue")
    rects2 = ax.bar(ind + width * 2, extrac, width, color = "red")
    ax.set_xlim(-width, len(ind) + width)
    ax.set_ylabel("Contributions/Extractions")
    ax.set_title("Alpha: " + str(0.85) + " Beta: " + str(0.4))
    xTickMarks = ["Agent" + str(i) for i in range(agents)]
    ax.set_xticks(ind + width)
    xtickNames = ax.set_xticklabels(xTickMarks)
    plt.setp(xtickNames, rotation = 45, fontsize = 10)    
    ax.legend((rects1[0], rects2[0]), ("Contributions", "Extractions"))
    fig.show()
    
    param_values2 = {"N": agents, "alpha": 1, "beta": 0.75, "eta": eta,
                "fa": fa, "r": r}
    batch2 = BatchRunner(Resource_Model, param_values2, iterations, runs, model_reporter)
    batch2.run_all()
    out2 = batch2.get_model_vars_dataframe()
    contrib2 = out2.Contributions[0]
    for j in range(1, iterations):
        subcon2 = out2.Contributions[j]
        contrib2 = [contrib2[i]+subcon2[i] for i in range(len(contrib2))]
    contrib2 = [(contrib2[i]/scale) for i in range(len(contrib2))]
    extrac2 = out.Takeouts[0]
    for j in range(1, iterations):
        subex2 = out2.Takeouts[j]
        extrac2 = [extrac2[i]+subex2[i] for i in range(len(extrac2))]
    extrac2 = [(extrac2[i]/scale) for i in range(len(extrac))]    
    fig2 = plt.figure()
    ax2 = fig2.add_subplot(111)
    rects3 = ax2.bar(ind + width, contrib2, width, color = "blue")
    rects4 = ax2.bar(ind + width * 2, extrac2, width, color = "red")
    ax2.set_xlim(-width, len(ind) + width)
    ax2.set_ylabel("Contributions/Extractions")
    ax2.set_title("Alpha: " + str(1) + " Beta: " + str(0.75))
    xTickMarks = ["Agent" + str(i) for i in range(agents)]
    ax2.set_xticks(ind + width)
    xtickNames = ax2.set_xticklabels(xTickMarks)
    plt.setp(xtickNames, rotation = 45, fontsize = 10)    
    ax2.legend((rects3[0], rects4[0]), ("Contributions", "Extractions"))
    fig2.show()

    param_values3 = {"N": agents, "alpha": 1, "beta": 1, "eta": eta,
                "fa": fa, "r": r}
    batch3 = BatchRunner(Resource_Model, param_values3, iterations, runs, model_reporter)
    batch3.run_all()
    out3 = batch3.get_model_vars_dataframe()
    contrib3 = out3.Contributions[0]
    for j in range(1, iterations):
        subcon3 = out3.Contributions[j]
        contrib3 = [contrib3[i]+subcon3[i] for i in range(len(contrib3))]
    contrib3 = [(contrib3[i]/scale) for i in range(len(contrib3))]
    extrac3 = out.Takeouts[0]
    for j in range(1, iterations):
        subex3 = out3.Takeouts[j]
        extrac3 = [extrac3[i]+subex3[i] for i in range(len(extrac3))]
    extrac3 = [(extrac3[i]/scale) for i in range(len(extrac))]    
    fig3 = plt.figure()
    ax3 = fig3.add_subplot(111)
    rects5 = ax3.bar(ind + width, contrib3, width, color = "blue")
    rects6 = ax3.bar(ind + width * 2, extrac3, width, color = "red")
    ax3.set_xlim(-width, len(ind) + width)
    ax3.set_ylabel("Contributions/Extractions")
    ax3.set_title("Alpha: " + str(1) + " Beta: " + str(1))
    xTickMarks = ["Agent" + str(i) for i in range(agents)]
    ax3.set_xticks(ind + width)
    xtickNames = ax3.set_xticklabels(xTickMarks)
    plt.setp(xtickNames, rotation = 45, fontsize = 10)    
    ax3.legend((rects5[0], rects6[0]), ("Contributions", "Extractions"))
    fig3.show()
    
if figure3_8 == 1:
    runs = 10
    agents = 5
    eta = 15
    alpha = 0 # starting value for alpha
    beta = 0 # starting value for beta
    iterations = 50
    groups = 100
    m = 0.001
    epsilon = 0.015 
    subiterations = 1
    f_a_range = 11
    out = []
    print("running...")
    for j in range(0, f_a_range):
        results = [0, 0, 0]
        for g in range(subiterations):
            sublist = imitation_model(iterations, groups, m, epsilon, j/10)
            results = [results[i]+sublist[i] for i in range(len(results))]
        results = (np.array(results))
        results = (results/subiterations)
        out.append(results)
    out = pd.DataFrame(out)
    #Visualization
    plt.plot(out[0])
    plt.xlabel("Number of times an asymmetric game is played")
    plt.ylabel("Average CPR value")
    plt.xticks(range(11))
    plt.show()
    
    alpha = plt.plot(out[1], label = "alpha", marker = "d")
    beta = plt.plot(out[2], label = "beta", marker = "s")
    plt.legend()
    plt.xticks(range(11))
    plt.xlabel("Number of times an asymmetric game is played")
    plt.ylabel("Average values for alpha and beta")
    plt.ylim(-1, 0.5)
    plt.hlines(0, 0, 10)
    plt.show()
    
#Printout of information on the running model
print("Model specs: ")
print("runs " + str(runs))
print("agents " + str(agents))
print ("iterations " + str(iterations))
if figure3_6 != 1:
    print("eta " + str(eta))
if figure3_8 != 1:
    print("fa " + str(fa))
print("")

if figure3_6 != 1 and figure3_7 != 1 and figure3_8 != 1:
    batch.run_all()
    out = batch.get_model_vars_dataframe() # Stores the collected data

#Saving the output as an analyzable .csv file
if figure3_6 != 1 and figure3_7 != 1 and figure3_8 != 1:
    filename = "v1.6_" + str(runs) + "runs_" + str(agents) + "agents_" + str(iterations) + "iterations_" + str(eta) + "eta_" + str(fa) + "fa.csv"
    out.to_csv(str(filename))
    print("Output saved as " + str(filename))
elif figure3_8 == 1:
    filename = str("results_" + str(eta) + "eta_" + str(iterations) + "iterations.csv")
    out.to_csv(str(filename))
    print("Output saved as " + str(filename))
    

#3D-Visualization
if visu3d == 1:
    out_one = out[out.alpha >= out.beta]
    out_two = out[out.beta > out.alpha]
    for j in out_two.index:
        out_two.set_value(j, "Generated_CPR", 0)
        out_two.set_value(j, "Gini_Contributions", 0)
        out_two.set_value(j, "Gini_Takeouts", 0)
    out = out_one.merge(out_two, how="outer")
    grouped_all = out.groupby(["alpha", "beta"]).mean()
    resource_values = grouped_all.Generated_CPR
    resource_list = np.array(resource_values)
    resource_list = ((resource_list) / runs)
    z_values = [resource_list[x:x+21] for x in range(0, len(resource_list), 21)]
    variables = []
    for j in range(-10, 11):
        variables.append(j/10)
        x = []
    for j in range(21):
        x.append(variables)      
    y = []
    for j in variables:
        sublist = []
        for s in range(21):
            sublist.append(j)
        y.append(sublist)
    data = (x, y, z_values)
    X, Y, Z = data
    contri_gini_values = grouped_all.Gini_Contributions
    contri_gini_list = np.array(contri_gini_values)
    a_values = [contri_gini_list[x:x+21] for x in range(0, len(contri_gini_list), 21)]
    data2 = (x, y, a_values)
    X, Y, A = data2
    takeout_gini_values = grouped_all.Gini_Takeouts
    takeout_gini_list = np.array(takeout_gini_values)
    b_values = [takeout_gini_list[x:x+21] for x in range(0, len(takeout_gini_list), 21)]
    data3 = (x, y, b_values)
    X, Y, B = data3
    def plot_3d(X, Y, Z, zaxis_label, azim, elev, invert_xaxis=True, invert_yaxis=True):
        fig = plt.figure()
        ax = fig.add_subplot(111, projection='3d')
        X = np.array(X)
        Y = np.array(Y)
        Z = np.array(Z)
        if invert_xaxis==True:
            plt.gca().invert_xaxis()
        if invert_yaxis==True:
            plt.gca().invert_yaxis()
        ax.plot_wireframe(X, Y, Z)
        ax.set_xlabel('Beta')
        ax.set_ylabel('Alpha')
        ax.set_zlabel(str(zaxis_label))
        ax.set_title(str(zaxis_label))
        ax.view_init(azim, elev)
        plt.show()
    
    plot_3d(X, Y, Z, "CPR level", 30, 60)
    plot_3d(Y, X, A, "Gini Contributions", 30, 60, invert_xaxis=False, invert_yaxis=False)
    plot_3d(X, Y, B, "Gini Takeouts", 30, 30, invert_xaxis=True, invert_yaxis=False)
